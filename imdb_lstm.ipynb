{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_lstm",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTk+SFgw8HIoQ8fI2EwLho",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cesar-claros/synergistic/blob/master/imdb_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4sBUso-gM_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "06caf4a6-d9e2-47f4-a801-3e61decf2388"
      },
      "source": [
        "!pip install torch\n",
        "!pip install gpytorch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Collecting gpytorch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/c7/0c31802b84fc55aa069943c844eaccb0e420e91d7f4ed07cc5e1d127c458/gpytorch-1.1.1.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 3.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: gpytorch\n",
            "  Building wheel for gpytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpytorch: filename=gpytorch-1.1.1-py2.py3-none-any.whl size=400467 sha256=635250c294c903838701c9ed95764788062a7a41a472aed4fb2ac783865aafd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/a5/29/4dafc0624adf678108e0067836556f0c72588e85d851d78ae0\n",
            "Successfully built gpytorch\n",
            "Installing collected packages: gpytorch\n",
            "Successfully installed gpytorch-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FymsszQy2n68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended #1\n",
        "! sudo apt-get install dvipng texlive-fonts-recommended #2\n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip #3\n",
        "! unzip type1cm.zip -d /tmp/type1cm #4\n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins  #5\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm #6\n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm #7\n",
        "! sudo texhash #8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gzdUCWgQOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "01aa03d8-167b-47d2-8544-4862fe6618d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pODgafakgcZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"drive/My Drive/NIPS2020/auxfunc/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/datasets/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/style/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/runs/\" ."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrowTWaDjHhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKBZk4trqzQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "bdbc26c1-e7f0-4bb0-955f-2600ce34f3e6"
      },
      "source": [
        "# Imports\n",
        "import io #Used as buffer\n",
        "import sys\n",
        "import matplotlib\n",
        "import tensorflow as tf # Keras model for MNIST \n",
        "# matplotlib.use('qt5Agg')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import auxfunc.sigfunc as sgn\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from scipy.stats import entropy, spearmanr\n",
        "from sklearn import model_selection, svm, ensemble, linear_model, pipeline, \\\n",
        "      tree, neighbors, discriminant_analysis, gaussian_process, preprocessing, impute, decomposition\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n",
        "plt.style.use(['ggplot','style/style.mplstyle'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPr-qGxurI6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Define LSTM architecture\n",
        "def LSTM_model(top_words, emb_vector_length, max_review_length, objective, reg=0.01):\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Embedding(top_words,emb_vector_length,input_length=max_review_length))\n",
        "    model.add(tf.keras.layers.LSTM(100))\n",
        "    if objective == 'svm':\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=1, kernel_initializer='uniform', activation='linear', kernel_regularizer=tf.keras.regularizers.l2(reg)\n",
        "        ))\n",
        "    elif objective == 'softmax':\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=1, kernel_initializer='uniform', activation='sigmoid'\n",
        "        ))\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYYvRG4AmtEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Signaling function fitting and evaluation\n",
        "def signalingFunction(X_train, y_train, y_train_pred_th, X_val, y_val, y_val_pred_th, X_test, y_test, y_test_pred_th, kernel='exponential', norm='l01'):\n",
        "    # X_train, X_val should be scaled\n",
        "    # Fit signaling function \n",
        "    exp = sgn.signaling(norm=norm) # idx = [train,test,val]\n",
        "    exp.fit(X_train, y_train, y_train_pred_th, kernel=kernel, n_iter=500, lr=0.01)\n",
        "    table_val = exp.evaluate(X_val, y_val, y_val_pred_th, rule_grid=np.linspace(0,3,30, endpoint=False))\n",
        "    table_test = exp.test(X_test, y_test, y_test_pred_th, table_val['rule'].to_numpy(), table_val['eta'].to_numpy())\n",
        "    table = pd.concat([table_val,table_test],axis=1)\n",
        "    return table, exp"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRVYBv5lxPJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Initialize model\n",
        "def init_model(input_dim, objective):\n",
        "    model = LSTM_model(top_words, emb_vector_length, max_review_length, objective)\n",
        "    if objective=='svm':\n",
        "        loss = tf.keras.losses.hinge\n",
        "        metric = ['hinge']\n",
        "\n",
        "    elif objective=='softmax':\n",
        "        loss = tf.keras.losses.binary_crossentropy\n",
        "        metric = ['accuracy']\n",
        "\n",
        "    model.compile(loss=loss,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=metric)\n",
        "    # model.summary()\n",
        "    print('loss={}'.format(loss.__name__))\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMK50NRixYI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Soft and thresholded output predictions\n",
        "def pred_output(model, X, objective):\n",
        "    if objective=='svm':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] >= 0 else 0 for i in y_pred_soft])\n",
        "    elif objective=='softmax':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] > 0.5 else 0 for i in y_pred_soft])\n",
        "    return y_pred_soft, y_pred_th"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nf3lDBxjZcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Jaccard similarity index\n",
        "def jaccard_similarity(list1, list2):\n",
        "    s1 = set(list1)\n",
        "    s2 = set(list2)\n",
        "    return len(s1.intersection(s2)) / len(s1.union(s2))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyWbCZTIjbiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Baseline comparison\n",
        "def baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf):\n",
        "      if clf=='svm':\n",
        "          direction = 'closer'\n",
        "          crit_val = np.abs(y_val_pred_soft.ravel())\n",
        "          crit_test = np.abs(y_test_pred_soft.ravel())\n",
        "      else:\n",
        "          direction = 'further'\n",
        "          p_val = np.concatenate((y_val_pred_soft,1-y_val_pred_soft),axis=1)\n",
        "          crit_val = entropy(p_val, axis=1, base=2)\n",
        "          p_test = np.concatenate((y_test_pred_soft,1-y_test_pred_soft),axis=1)\n",
        "          crit_test = entropy(p_test, axis=1, base=2)\n",
        "      \n",
        "      critFunc = sgn.critEvaluation(norm='l01',direction=direction)\n",
        "      d_val = critFunc.evaluate(y_val, y_val_pred_th, crit_val)\n",
        "      d_test = critFunc.test(y_test, y_test_pred_th, crit_test, d_val['thresh'].to_numpy())\n",
        "      crit_table = pd.concat([d_val,d_test],axis=1)\n",
        "\n",
        "      gamma = table['rule'].to_numpy().reshape(-1,1)\n",
        "      f_test = exp.gpr_mean_test + gamma*np.sqrt(exp.gpr_var_test)\n",
        "      eta = table['eta'].to_numpy().reshape(-1,1)\n",
        "      theta = crit_table['thresh'].to_numpy().reshape(-1,1)\n",
        "      if direction == 'closer':\n",
        "        f_mask, f_idx = np.nonzero(f_test>eta)\n",
        "      else:\n",
        "        f_mask, f_idx = np.nonzero(f_test<eta)\n",
        "      crit_mask, crit_idx = np.nonzero(crit_test.reshape(1,-1)<theta)\n",
        "      print(list(np.unique(f_mask)))\n",
        "      print(list(np.unique(crit_mask)))\n",
        "      print(f_test.shape[0])\n",
        "      shared = set(list(np.unique(f_mask))).intersection(set(list(np.unique(crit_mask))))\n",
        "      J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan for i in range(f_test.shape[0])]\n",
        "      # if (list(np.unique(f_mask))==list(np.unique(crit_mask))):\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) for i in np.unique(f_mask)]\n",
        "      # else:\n",
        "      #   shared = set(a).intersection(set(b))\n",
        "      #   union = set(a).union(set(b))\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan  for i in union]\n",
        "      crit_table['jaccard']=J\n",
        "      Sp = [spearmanr(f_test[i,:],crit_test)[0] for i in range(f_test.shape[0])]\n",
        "      crit_table['spearman'] = Sp\n",
        "      crit_table['gamma'] = gamma\n",
        "      return crit_table"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3VCXn3_rTYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "16cdef74-a2aa-4f2d-f6dd-6612cd4ad06a"
      },
      "source": [
        "# %%\n",
        "# INITIALIZATION\n",
        "# ==============\n",
        "# EXPERIMENT SETUP\n",
        "# ================\n",
        "top_words = 5000\n",
        "max_review_length = 500\n",
        "emb_vector_length = 32\n",
        "# Load data set\n",
        "(Data_X, Data_y), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=top_words)\n",
        "Data_X = tf.keras.preprocessing.sequence.pad_sequences(Data_X, maxlen=max_review_length)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "print(\"Number of original training examples:\", len(Data_X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jsIZNLPri8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a01050c3-6c54-49c4-bcbb-05756b251530"
      },
      "source": [
        "# For reproducibility\n",
        "tf.random.set_seed(54321)\n",
        "np.random.seed(12345)\n",
        "torch.manual_seed(0)\n",
        "#%%\n",
        "# Assign labels\n",
        "report_table = []\n",
        "report_criteria = []\n",
        "report_plot = []\n",
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=123)\n",
        "clf = 'softmax'\n",
        "addPredictions = True\n",
        "applyPCA = True\n",
        "accuracy = 0\n",
        "for sample, test in kf.split(Data_X):\n",
        "    sample = sample[:12500]\n",
        "    test = test[:2000]\n",
        "    X = Data_X[sample]\n",
        "    y = Data_y[sample]\n",
        "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "    X_test = Data_X[test]\n",
        "    y_test = Data_y[test]\n",
        "\n",
        "    # TRAINING MODEL\n",
        "    model = init_model(input_dim=X.shape[1], objective=clf)\n",
        "    model.fit(X_train, y_train, batch_size=64, epochs=5, verbose=0, validation_data=(X_val, y_val))\n",
        "    # X_test = scaleX.transform(imputeX.transform(X_test))\n",
        "\n",
        "    y_train_pred_soft, y_train_pred_th = pred_output(model, X_train, clf)\n",
        "    print('accuracy(Train)={}'.format(np.sum(y_train==y_train_pred_th)/np.size(y_train)))\n",
        "    y_val_pred_soft, y_val_pred_th = pred_output(model, X_val, clf)\n",
        "    # print('accuracy(Val)={}'.format(np.sum(y_val==y_val_pred_th)/np.size(y_val)))\n",
        "    y_test_pred_soft, y_test_pred_th = pred_output(model, X_test, clf)\n",
        "\n",
        "    layer_outputs = [layer.output for layer in model.layers] \n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "    X_train_GP = activation_model.predict(X_train)[1]\n",
        "    X_val_GP = activation_model.predict(X_val)[1]\n",
        "    X_test_GP = activation_model.predict(X_test)[1]\n",
        "\n",
        "    if addPredictions:\n",
        "            # Add predictions\n",
        "            X_train_GP = np.concatenate((X_train, y_train_pred_soft), axis=1)\n",
        "            X_val_GP = np.concatenate((X_val, y_val_pred_soft), axis=1)\n",
        "            X_test_GP = np.concatenate((X_test, y_test_pred_soft), axis=1)\n",
        "    scaleX_GP = preprocessing.StandardScaler().fit(np.concatenate((X_train_GP, X_val_GP), axis=0))\n",
        "    X_train_GP = scaleX_GP.transform(X_train_GP)\n",
        "    X_val_GP = scaleX_GP.transform(X_val_GP)\n",
        "    X_test_GP = scaleX_GP.transform(X_test_GP)\n",
        "    if applyPCA:\n",
        "            pca_GP = decomposition.PCA(.99).fit(np.concatenate((X_train_GP, X_val_GP), axis=0)) # set percentage of energy preserved by PCA\n",
        "            # Apply PCA transform to all sets\n",
        "            X_train_GP = pca_GP.transform(X_train_GP)\n",
        "            X_val_GP = pca_GP.transform(X_val_GP)\n",
        "            X_test_GP = pca_GP.transform(X_test_GP)\n",
        "\n",
        "    table, exp = signalingFunction(X_train_GP, y_train, y_train_pred_th, X_val_GP, y_val, y_val_pred_th, X_test_GP, y_test, y_test_pred_th)\n",
        "    report_table.append(table)\n",
        "    # Baseline for comparison\n",
        "    crit_table = baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf)\n",
        "    report_criteria.append(crit_table)\n",
        "\n",
        "    score = np.sum(y_val==y_val_pred_th)/np.size(y_val)\n",
        "    if accuracy < score:\n",
        "      accuracy = score\n",
        "      exp_best = exp\n",
        "      table_best = table\n",
        "      crit_table_best = crit_table\n",
        "      y_test_pred_soft_best = y_test_pred_soft\n",
        "\n",
        "    del(model)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9306\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 492/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 493/500 - Loss: 0.048  noise: 0.034\n",
            "Iter 494/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 495/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 496/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 497/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 498/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 499/500 - Loss: 0.047  noise: 0.034\n",
            "Iter 500/500 - Loss: 0.047  noise: 0.034\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9308\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: 0.046  noise: 0.034\n",
            "Iter 492/500 - Loss: 0.045  noise: 0.034\n",
            "Iter 493/500 - Loss: 0.045  noise: 0.034\n",
            "Iter 494/500 - Loss: 0.045  noise: 0.034\n",
            "Iter 495/500 - Loss: 0.045  noise: 0.034\n",
            "Iter 496/500 - Loss: 0.046  noise: 0.034\n",
            "Iter 497/500 - Loss: 0.046  noise: 0.034\n",
            "Iter 498/500 - Loss: 0.046  noise: 0.034\n",
            "Iter 499/500 - Loss: 0.045  noise: 0.034\n",
            "Iter 500/500 - Loss: 0.045  noise: 0.034\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.8676\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: 0.330  noise: 0.057\n",
            "Iter 492/500 - Loss: 0.329  noise: 0.057\n",
            "Iter 493/500 - Loss: 0.329  noise: 0.057\n",
            "Iter 494/500 - Loss: 0.330  noise: 0.057\n",
            "Iter 495/500 - Loss: 0.330  noise: 0.057\n",
            "Iter 496/500 - Loss: 0.330  noise: 0.057\n",
            "Iter 497/500 - Loss: 0.330  noise: 0.057\n",
            "Iter 498/500 - Loss: 0.329  noise: 0.057\n",
            "Iter 499/500 - Loss: 0.329  noise: 0.057\n",
            "Iter 500/500 - Loss: 0.329  noise: 0.057\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9575\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 492/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 493/500 - Loss: -0.176  noise: 0.023\n",
            "Iter 494/500 - Loss: -0.176  noise: 0.023\n",
            "Iter 495/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 496/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 497/500 - Loss: -0.176  noise: 0.023\n",
            "Iter 498/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 499/500 - Loss: -0.177  noise: 0.023\n",
            "Iter 500/500 - Loss: -0.177  noise: 0.023\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.929\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 492/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 493/500 - Loss: 0.058  noise: 0.035\n",
            "Iter 494/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 495/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 496/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 497/500 - Loss: 0.058  noise: 0.035\n",
            "Iter 498/500 - Loss: 0.058  noise: 0.035\n",
            "Iter 499/500 - Loss: 0.059  noise: 0.035\n",
            "Iter 500/500 - Loss: 0.059  noise: 0.035\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWPUAct1q2Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logs_base_dir = \"runs/\"\n",
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNsdkAGq5Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##%\n",
        "# Boxplot (loss reduction in test set)\n",
        "report_table_concat = pd.concat(report_table)\n",
        "cols_table = ['p_value','rho_user','%reduction_test']\n",
        "df_boxplot_table = pd.DataFrame(report_table_concat[cols_table])\n",
        "df_boxplot_table['label'] = df_boxplot_table.shape[0]*['$f(x)$']\n",
        "report_criteria_concat = pd.concat(report_criteria)\n",
        "columns_crit = ['rho_user','%reduction_test']\n",
        "df_boxplot_crit = pd.DataFrame(report_criteria_concat[columns_crit])\n",
        "df_boxplot_crit['label'] = df_boxplot_crit.shape[0]*['$g(x)$']\n",
        "# p-value median\n",
        "p_value_by_row_index = df_boxplot_table['p_value'].groupby(df_boxplot_table.index)\n",
        "p_value_median = p_value_by_row_index.median()\n",
        "# Boxplot (jaccard index in test set)\n",
        "columns_jac = ['rho_user','jaccard']\n",
        "df_jaccard = pd.DataFrame(report_criteria_concat[columns_jac])\n",
        "# Unfiltered Result dataframes\n",
        "cols_fx = ['rho_user','%reduction_val','budget','%reduction_test']\n",
        "results_fx = pd.DataFrame(report_table_concat[cols_fx])\n",
        "cols_fxgx = ['rho_user','%reduction_test', 'jaccard']\n",
        "results_fxgx = pd.concat([df_boxplot_table[cols_fxgx[:2]], df_boxplot_crit[cols_fxgx[1]], df_jaccard[cols_fxgx[2]]], axis=1)\n",
        "# Filter experiments with p_value > 0.05\n",
        "df_boxplot_crit = df_boxplot_crit.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "df_jaccard = df_jaccard.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "df_boxplot_table = df_boxplot_table.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "# Boxplot with filtered values only\n",
        "frames = [df_boxplot_table, df_boxplot_crit]\n",
        "df = pd.concat(frames)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OumIYSVNq7Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avoid plotting when median(p_value)>0.5\n",
        "for i in range(p_value_median.shape[0]):\n",
        "    if p_value_median.iloc[i]>0.05:\n",
        "      df.loc[df.index==i,'%reduction_test'] = np.nan\n",
        "      df_jaccard.loc[df_jaccard.index==i, 'jaccard'] = np.nan"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6d4xyQvq952",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "6b9825c7-0791-4a56-9299-a6335308d7ef"
      },
      "source": [
        "# Dataframe for results f(x)\n",
        "results_fx_by_row_index = results_fx.groupby(results_fx.index)\n",
        "fx_median = results_fx_by_row_index.median()\n",
        "fx_q1 = results_fx_by_row_index.quantile(q=0.25)\n",
        "fx_q3 = results_fx_by_row_index.quantile(q=0.75)\n",
        "# Signaling function statistics (median(q1-q3)) LaTex\n",
        "output_fx = io.StringIO()\n",
        "numRows = fx_median.shape[0]\n",
        "numCols = fx_median.shape[1]\n",
        "output_fx.write(\"results_fx (\\\\rho|%reduction_val|sig_rate|%reduction_test|H0)\\n\")\n",
        "output_fx.write(\"----------\\n\")\n",
        "for i in range(numRows):\n",
        "  row = [r'{:.2f}'.format(val1) if p_value_median[i]>0.05 and j==0 else r'{}' if p_value_median[i]>0.05 and j!=0\\\n",
        "         else r'{:.2f}'.format(val1) if (j==0) else r'{:.2f}({:.2f}-{:.2f})'.format(val1,val2,val3) if (j==2)\\\n",
        "         else r'{:.1f}({:.1f}-{:.1f})'.format(val1,val2,val3) for val1,val2,val3,j in zip(fx_median.iloc[i],fx_q1.iloc[i],fx_q3.iloc[i],range(numCols))]\n",
        "  output_fx.write(\"{{}} & {{}} & %s & {H0} \\\\\\\\\\n\".format(H0=r'$\\surd$' if p_value_median[i]<=0.05 else r'$\\times$')%(\" & \".join(row)))\n",
        "print(output_fx.getvalue())"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results_fx (\\rho|%reduction_val|sig_rate|%reduction_test|H0)\n",
            "----------\n",
            "{} & {} & 0.01 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.05 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.10 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.15 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.20 & {} & {} & {} & $\\times$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjL-JtRhrC6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "57976a03-3064-47cb-efbf-5d9238a399df"
      },
      "source": [
        "# Dataframe for comparison f(x)-g(x)\n",
        "results_fxgx_by_row_index = results_fxgx.groupby(results_fxgx.index)\n",
        "fxgx_median = results_fxgx_by_row_index.median()\n",
        "fxgx_q1 = results_fxgx_by_row_index.quantile(q=0.25)\n",
        "fxgx_q3 = results_fxgx_by_row_index.quantile(q=0.75)\n",
        "# Baseline comparison statistics (median(q1-q3)) LaTex\n",
        "output_fxgx = io.StringIO()\n",
        "numRows = fxgx_median.shape[0]\n",
        "numCols = fxgx_median.shape[1]\n",
        "output_fxgx.write(\"results_fxgx (\\\\rho|%reduction_test(fx)|%reduction_test(fxgx)|Jaccard|H0\\n\")\n",
        "output_fxgx.write(\"------------\\n\")\n",
        "for i in range(numRows):\n",
        "  row = [r'{:.2f}'.format(val1) if p_value_median[i]>0.05 and j==0 else r'{}' if p_value_median[i]>0.05 and j!=0\\\n",
        "         else r'{:.2f}'.format(val1) if (j==0) else r'{:.2f}({:.2f}-{:.2f})'.format(val1,val2,val3) if (j==3)\\\n",
        "         else r'{:.1f}({:.1f}-{:.1f})'.format(val1,val2,val3) for val1,val2,val3,j in zip(fxgx_median.iloc[i],fxgx_q1.iloc[i],fxgx_q3.iloc[i],range(numCols))]\n",
        "  output_fxgx.write(\"{{}} & {{}} & %s & {H0} \\\\\\\\\\n\".format(H0=r'$\\surd$' if p_value_median[i]<=0.05 else r'$\\times$')%(\" & \".join(row)))\n",
        "print(output_fxgx.getvalue())"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results_fxgx (\\rho|%reduction_test(fx)|%reduction_test(fxgx)|Jaccard|H0\n",
            "------------\n",
            "{} & {} & 0.01 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.05 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.10 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.15 & {} & {} & {} & $\\times$ \\\\\n",
            "{} & {} & 0.20 & {} & {} & {} & $\\times$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0X7KJ6trNGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Save results in csv fomat\n",
        "path_csv = \"drive/My Drive/NIPS2020/results/imdb/results_{clf}_yhat{yhat}_pca{pca}.csv\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "results = pd.concat([results_fx, results_fxgx], keys=['fx', 'fxgx'], axis=1).to_csv(path_csv, index=True, header=True)\n",
        "# Save results in tex fomat\n",
        "L = [output_fx.getvalue(),output_fxgx.getvalue()]\n",
        "path_txt = \"drive/My Drive/NIPS2020/results/imdb/results_{clf}_yhat{yhat}_pca{pca}.txt\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "txt = open(path_txt, \"w\") \n",
        "txt.writelines(L) \n",
        "txt.close() #to change file access modes"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTFKkXsrQOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "463e9e31-5418-45e7-9778-c176df5bab4e"
      },
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(15, 5.1), constrained_layout=False, dpi=90)\n",
        "pal = sns.color_palette('Paired')\n",
        "sns.boxplot(x=df['rho_user'], y=df['%reduction_test'], hue='label', data=df, ax=ax[0], palette=pal)\n",
        "ax[0].set_xlabel(r'budget $\\rho$')\n",
        "ax[0].set_ylabel(r'Loss reduction $r_{test}(\\%)$')\n",
        "ax[0].legend(loc='upper left')\n",
        "pal = sns.color_palette('BuGn_r')\n",
        "sns.boxplot(x=df_jaccard['rho_user'], y=df_jaccard['jaccard'], data=df_jaccard, ax=ax[1], palette=pal)\n",
        "ax[1].set_xlabel(r'budget $\\rho$')\n",
        "ax[1].set_ylabel(r'Jaccard index $J$')\n",
        "plt.tight_layout()\n",
        "path_fig_fxgx = \"drive/My Drive/NIPS2020/results/imdb/fig_fxgx_{clf}_yhat{yhat}_pca{pca}.pdf\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "plt.savefig(path_fig_fxgx, bbox_inches='tight', facecolor='w')"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x459 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlQtQPDGFE9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reverse lookup\n",
        "INDEX_FROM = 3\n",
        "word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj6x1QVqcRgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0d5f210d-340d-4ee4-f195-dc3b053b97c8"
      },
      "source": [
        "rho = 0.01\n",
        "rule = table_best.loc[table_best.rho_user == rho]['rule'].to_numpy()\n",
        "eta = table_best.loc[table_best.rho_user == rho]['eta'].to_numpy()[0]\n",
        "theta = crit_table_best.loc[crit_table_best.rho_user == rho]['thresh'].to_numpy()[0]\n",
        "f_test = exp_best.gpr_mean_test+rule*np.sqrt(exp_best.gpr_var_test)\n",
        "top_n = 20 # Top n selected instances in test set\n",
        "top_f_idx = np.argpartition(f_test, -top_n)[-top_n:]\n",
        "if clf=='svm':\n",
        "    crit_test = np.abs(y_test_pred_soft_best.ravel())\n",
        "    top_crit_idx = np.argpartition(crit_test, top_n)[:top_n]\n",
        "elif clf=='softmax':\n",
        "    p_test = np.concatenate((y_test_pred_soft_best,1-y_test_pred_soft_best),axis=1)\n",
        "    crit_test = entropy(p_test, axis=1, base=2)\n",
        "    top_crit_idx = np.argpartition(crit_test, -top_n)[-top_n:]\n",
        "output_text = io.StringIO()\n",
        "print('eta={},theta={}'.format(eta,theta))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eta=0.46235495805740356,theta=0.9987918138504028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqv4gVyc1kF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "3a89e78d-25d7-4945-c55a-02377c19e422"
      },
      "source": [
        "output_text.write(\"top_n={}, rho_user={}, g(x)={}, addh_hat={}, PCA={}\\n\".format(top_n,rho,clf, addPredictions, applyPCA))\n",
        "output_text.write(\"|f(x)>eta|={}(eta={:.3f}), |g(x)>theta|={}(theta={:.3f})\\n\".format(np.sum(f_test>eta), eta, np.sum(crit_test<theta) if clf=='svm' else np.sum(crit_test>theta), theta))\n",
        "output_text.write(\"\\nTop misclassfied instances picked by f(x)\\n\")\n",
        "output_text.write(\"-----------------------------------------\\n\")\n",
        "for i in top_f_idx:\n",
        "  cond = f_test[i]>eta\n",
        "  if y_test[i] != y_test_pred_th[i] and cond:\n",
        "    output_text.write(' '.join([id_to_word[id] for id in X_test[i,:] if id!=0])+\\\n",
        "        '\\n y={}'.format(y_test[i])+', y_pred={}'.format(y_test_pred_th[i])+\\\n",
        "        ', g(x)({})={:.3f}'.format('D' if clf=='svm' else 'H', crit_test[i])+\\\n",
        "        ', f(x)={:.3f}'.format(f_test[i])+'\\n\\n')\n",
        "print(output_text.getvalue())"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=27(eta=0.462), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "\n",
            "<START> i saw this little <UNK> gem two days after seeing <UNK> <UNK> make no mistake about it <UNK> is a <UNK> <UNK> ride be it american or european <UNK> <UNK> <UNK> or as it is being called in the u s <UNK> <UNK> is a tale of a young 15 year old girl played by <UNK> <UNK> who at times resembles a young <UNK> <UNK> acts the cool <UNK> girl who wants to be on the school <UNK> team just to be close to another attractive girl <UNK> <UNK> it's more than obvious that marie is more than attracted to <UNK> <UNK> among all of this is <UNK> rather <UNK> <UNK> friend anne who just wants a boyfriend like any other girl her age along the way we are shown the usual <UNK> of teen <UNK> broken hearts shop <UNK> <UNK> and or drug use <UNK> sex etc this is a quiet little film that takes time to work it's way into your system michael bay fans take note the pacing here is s l o w so <UNK> clear but if you have no problem with this water <UNK> is a <UNK> no rating here but would pull down a hard r due to language nudity adult situations\n",
            " y=1, y_pred=0, g(x)(H)=0.745, f(x)=0.556\n",
            "\n",
            "<START> the reviewer who called this movie a <UNK> has clearly missed the point it's obvious he hasn't been young or innocent in a very long time or he might have understood that the tragedy of it was that the well meaning young characters actually thought they could make a difference by putting up <UNK> and holding a <UNK> for peace if only it was that easy but the <UNK> sit and <UNK> at people who <UNK> try their best to make things better as the situation gets worse and worse every single day well if you're not part of the solution you're part of the problem br br the central theme is that revenge <UNK> more revenge which <UNK> even more in an ever <UNK> <UNK> both sides will tell you tales of <UNK> committed by the other side which they think justify their <UNK> even more in <UNK> where does it end and apparently he missed the <UNK> of the <UNK> <UNK> to in the name which was that people living in <UNK> <UNK> are strangely cut off from the ugly <UNK> of what is going on all around them which is partly why they seemed so naive he also seemed to think that <UNK> could <UNK> through the <UNK> without a problem which tells me he wasn't paying attention when <UNK> related the <UNK> and problems he had <UNK> br br i found it very brave of the director the screenplay writer and both star <UNK> lovers to <UNK> the <UNK> <UNK> story to a modern troubled land and to make both lovers male let's be honest here very few people would have a problem if one of them had been a female young love wins all hearts but when people's <UNK> with their sexuality is added to the fact that incredibly these same people would rather have them hate each other then the conclusion is inevitable\n",
            " y=1, y_pred=0, g(x)(H)=0.973, f(x)=0.560\n",
            "\n",
            "<START> i've read one comment which <UNK> this film trash and a waste br br of time i think this person got their political <UNK> <UNK> a bit br br too much br br i just rented the new <UNK> <UNK> of both yellow and blue br br these films although hardly great have at least become of br br historical interest as to the so called <UNK> student br br political social movement of the late <UNK> br br i hadn't seen either picture and from their notorious reputation i br br was expecting some real porn there isn't any there is <UNK> br br nudity including the still <UNK> <UNK> male nudity <UNK> br br <UNK> 17 the <UNK> x in the u s but i wasn't expecting the films br br in your face <UNK> <UNK> message br br though it tends to the simplistic i thought it <UNK> made br br its points well both films <UNK> had me laughing out loud br br and the director's commentary made it clear there was plenty of br br parody in the film especially the supposedly <UNK> sex br br scenes the first such scene is very realistic the lead couple is br br clumsy inept funny and endearing in their first <UNK> scene br br the second which caused the most <UNK> has <UNK> br br <UNK> and <UNK> and the last is the end of an angry fight br br that is believable br br the extras include an <UNK> introduction to the film an br br interview with the original american <UNK> and his attorney br br <UNK> from trial <UNK> in the u s and a <UNK> commentary br br by the director on some scenes br br this is the film that blue <UNK> wouldn't let alone and led to the br br <UNK> <UNK> interest with no social redeeming value standard br br that thankfully still stands br br those with an interest in the <UNK> of history will find this a must br br see\n",
            " y=1, y_pred=0, g(x)(H)=0.989, f(x)=0.576\n",
            "\n",
            "<START> i wanted to read the other comments before leaving my review and the majority <UNK> rules this movie is <UNK> from the acting to the non realistic animation to the countless errors i was actually hoping that the <UNK> would have been extended by a stretch of the imagination can't <UNK> <UNK> without <UNK> the <UNK> <UNK> cannot be <UNK> unless you have <UNK> that tiny little fan that was going was not <UNK> by any stretch to lower the <UNK> <UNK> the one thing i thought was quite <UNK> is when they <UNK> the back <UNK> touched down and then the nose one broke off thus <UNK> the plane with both back <UNK> in the air how did the captain <UNK> left and right <UNK> to <UNK> that weren't touching the ground did they forget the spoilers word to the director find out all you can about <UNK> before attempting a plane movie sorry for the technical <UNK> but i give this movie 1 10\n",
            " y=0, y_pred=1, g(x)(H)=0.995, f(x)=0.672\n",
            "\n",
            "\n",
            "Top misclassfied instances picked by g(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "<START> this had to be one of the most god awful <UNK> ever and is only saved by 2 matches the hardcore match between edge and <UNK> <UNK> also <UNK> <UNK> against <UNK> <UNK> the main event between <UNK> and <UNK> h was a complete <UNK> and to be honest i nearly fell asleep it was so <UNK> the <UNK> match was not worthy of having the <UNK> appear in it and the match between the <UNK> man and <UNK> t was a complete joke if you are really a big fan of the <UNK> and have missed the early days of the <UNK> and the <UNK> 17 and <UNK> you'll probably love this but i found that this <UNK> left a lot to be desired\n",
            " y=0, y_pred=1, g(x)(H)=1.000, f(x)=0.419\n",
            "<START> there are so many good things to say about this <UNK> movie br br <UNK> maybe in <UNK> but not in <UNK> this is about the best of its genre that i have ever seen a grade a effort by universal the script is well done imaginative and without fault writing credits howard <UNK> original story douglas <UNK> story john <UNK> screenplay director <UNK> <UNK> handled the complex story and story locations very well no <UNK> on the loads of extras and locations i loved <UNK> <UNK> jimmy <UNK> mother in <UNK> a wonderful <UNK> the <UNK> lead <UNK> <UNK> is a beauty and handled her part with grace and <UNK> for her karloff husband lugosi likewise was <UNK> <UNK> i think this is the best part i remember seeing him in as i said there were so many good things the african discovery of the <UNK> <UNK> the melting of the stone <UNK> somewhat reminiscent of the ten little indians in and then there were none <UNK> <UNK> the barry <UNK> version the <UNK> of <UNK> in the dark <UNK> mother played by <UNK> <UNK> cooper with <UNK> and because of all these <UNK> i found myself believing in the science it portrayed i guess <UNK> the mark of a good piece of art\n",
            " y=1, y_pred=0, g(x)(H)=0.999, f(x)=0.072\n",
            "<START> this movie is good for tv i like it because i'm a huge fan of disaster films even though this is a family film <UNK> on the film from the book is half and half they got the characters names right but in the book there was no storm <UNK> the the car scene involving the <UNK> family running away from the <UNK> wasn't in the book instead it involved dan <UNK> and his friend riding with a police officer on their way to the police station for safety and in the book dan and his friend are both 12 years old thats all i can think of overall this was a good movie even though it could of have been a little more accurate to the book did you know the book was based on a true story of a series of <UNK> <UNK> a small <UNK> town in 1980\n",
            " y=1, y_pred=0, g(x)(H)=1.000, f(x)=0.090\n",
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=27(eta=0.462), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "\n",
            "<START> i saw this little <UNK> gem two days after seeing <UNK> <UNK> make no mistake about it <UNK> is a <UNK> <UNK> ride be it american or european <UNK> <UNK> <UNK> or as it is being called in the u s <UNK> <UNK> is a tale of a young 15 year old girl played by <UNK> <UNK> who at times resembles a young <UNK> <UNK> acts the cool <UNK> girl who wants to be on the school <UNK> team just to be close to another attractive girl <UNK> <UNK> it's more than obvious that marie is more than attracted to <UNK> <UNK> among all of this is <UNK> rather <UNK> <UNK> friend anne who just wants a boyfriend like any other girl her age along the way we are shown the usual <UNK> of teen <UNK> broken hearts shop <UNK> <UNK> and or drug use <UNK> sex etc this is a quiet little film that takes time to work it's way into your system michael bay fans take note the pacing here is s l o w so <UNK> clear but if you have no problem with this water <UNK> is a <UNK> no rating here but would pull down a hard r due to language nudity adult situations\n",
            " y=1, y_pred=0, g(x)(H)=0.745, f(x)=0.556\n",
            "\n",
            "<START> the reviewer who called this movie a <UNK> has clearly missed the point it's obvious he hasn't been young or innocent in a very long time or he might have understood that the tragedy of it was that the well meaning young characters actually thought they could make a difference by putting up <UNK> and holding a <UNK> for peace if only it was that easy but the <UNK> sit and <UNK> at people who <UNK> try their best to make things better as the situation gets worse and worse every single day well if you're not part of the solution you're part of the problem br br the central theme is that revenge <UNK> more revenge which <UNK> even more in an ever <UNK> <UNK> both sides will tell you tales of <UNK> committed by the other side which they think justify their <UNK> even more in <UNK> where does it end and apparently he missed the <UNK> of the <UNK> <UNK> to in the name which was that people living in <UNK> <UNK> are strangely cut off from the ugly <UNK> of what is going on all around them which is partly why they seemed so naive he also seemed to think that <UNK> could <UNK> through the <UNK> without a problem which tells me he wasn't paying attention when <UNK> related the <UNK> and problems he had <UNK> br br i found it very brave of the director the screenplay writer and both star <UNK> lovers to <UNK> the <UNK> <UNK> story to a modern troubled land and to make both lovers male let's be honest here very few people would have a problem if one of them had been a female young love wins all hearts but when people's <UNK> with their sexuality is added to the fact that incredibly these same people would rather have them hate each other then the conclusion is inevitable\n",
            " y=1, y_pred=0, g(x)(H)=0.973, f(x)=0.560\n",
            "\n",
            "<START> i've read one comment which <UNK> this film trash and a waste br br of time i think this person got their political <UNK> <UNK> a bit br br too much br br i just rented the new <UNK> <UNK> of both yellow and blue br br these films although hardly great have at least become of br br historical interest as to the so called <UNK> student br br political social movement of the late <UNK> br br i hadn't seen either picture and from their notorious reputation i br br was expecting some real porn there isn't any there is <UNK> br br nudity including the still <UNK> <UNK> male nudity <UNK> br br <UNK> 17 the <UNK> x in the u s but i wasn't expecting the films br br in your face <UNK> <UNK> message br br though it tends to the simplistic i thought it <UNK> made br br its points well both films <UNK> had me laughing out loud br br and the director's commentary made it clear there was plenty of br br parody in the film especially the supposedly <UNK> sex br br scenes the first such scene is very realistic the lead couple is br br clumsy inept funny and endearing in their first <UNK> scene br br the second which caused the most <UNK> has <UNK> br br <UNK> and <UNK> and the last is the end of an angry fight br br that is believable br br the extras include an <UNK> introduction to the film an br br interview with the original american <UNK> and his attorney br br <UNK> from trial <UNK> in the u s and a <UNK> commentary br br by the director on some scenes br br this is the film that blue <UNK> wouldn't let alone and led to the br br <UNK> <UNK> interest with no social redeeming value standard br br that thankfully still stands br br those with an interest in the <UNK> of history will find this a must br br see\n",
            " y=1, y_pred=0, g(x)(H)=0.989, f(x)=0.576\n",
            "\n",
            "<START> i wanted to read the other comments before leaving my review and the majority <UNK> rules this movie is <UNK> from the acting to the non realistic animation to the countless errors i was actually hoping that the <UNK> would have been extended by a stretch of the imagination can't <UNK> <UNK> without <UNK> the <UNK> <UNK> cannot be <UNK> unless you have <UNK> that tiny little fan that was going was not <UNK> by any stretch to lower the <UNK> <UNK> the one thing i thought was quite <UNK> is when they <UNK> the back <UNK> touched down and then the nose one broke off thus <UNK> the plane with both back <UNK> in the air how did the captain <UNK> left and right <UNK> to <UNK> that weren't touching the ground did they forget the spoilers word to the director find out all you can about <UNK> before attempting a plane movie sorry for the technical <UNK> but i give this movie 1 10\n",
            " y=0, y_pred=1, g(x)(H)=0.995, f(x)=0.672\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhsLRvmXO-Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aef2df1a-5a1c-4f33-98b4-cfe6cb8c12a6"
      },
      "source": [
        "output_text.write(\"\\nTop misclassfied instances picked by g(x)\\n\")\n",
        "output_text.write(\"-----------------------------------------\\n\")\n",
        "for i in top_crit_idx:\n",
        "  cond = crit_test[i]<theta if clf=='svm' else crit_test[i]>theta\n",
        "  if y_test[i] != y_test_pred_th[i]:\n",
        "    output_text.write(' '.join([id_to_word[id] for id in X_test[i,:] if id!=0])+\\\n",
        "        '\\n y={}'.format(y_test[i])+', y_pred={}'.format(y_test_pred_th[i])+\\\n",
        "        ', g(x)({})={:.3f}'.format('D' if clf=='svm' else 'H', crit_test[i])+\\\n",
        "        ', f(x)={:.3f}'.format(f_test[i])+'\\n\\n')\n",
        "print(output_text.getvalue())"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=27(eta=0.462), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "\n",
            "<START> i saw this little <UNK> gem two days after seeing <UNK> <UNK> make no mistake about it <UNK> is a <UNK> <UNK> ride be it american or european <UNK> <UNK> <UNK> or as it is being called in the u s <UNK> <UNK> is a tale of a young 15 year old girl played by <UNK> <UNK> who at times resembles a young <UNK> <UNK> acts the cool <UNK> girl who wants to be on the school <UNK> team just to be close to another attractive girl <UNK> <UNK> it's more than obvious that marie is more than attracted to <UNK> <UNK> among all of this is <UNK> rather <UNK> <UNK> friend anne who just wants a boyfriend like any other girl her age along the way we are shown the usual <UNK> of teen <UNK> broken hearts shop <UNK> <UNK> and or drug use <UNK> sex etc this is a quiet little film that takes time to work it's way into your system michael bay fans take note the pacing here is s l o w so <UNK> clear but if you have no problem with this water <UNK> is a <UNK> no rating here but would pull down a hard r due to language nudity adult situations\n",
            " y=1, y_pred=0, g(x)(H)=0.745, f(x)=0.556\n",
            "\n",
            "<START> the reviewer who called this movie a <UNK> has clearly missed the point it's obvious he hasn't been young or innocent in a very long time or he might have understood that the tragedy of it was that the well meaning young characters actually thought they could make a difference by putting up <UNK> and holding a <UNK> for peace if only it was that easy but the <UNK> sit and <UNK> at people who <UNK> try their best to make things better as the situation gets worse and worse every single day well if you're not part of the solution you're part of the problem br br the central theme is that revenge <UNK> more revenge which <UNK> even more in an ever <UNK> <UNK> both sides will tell you tales of <UNK> committed by the other side which they think justify their <UNK> even more in <UNK> where does it end and apparently he missed the <UNK> of the <UNK> <UNK> to in the name which was that people living in <UNK> <UNK> are strangely cut off from the ugly <UNK> of what is going on all around them which is partly why they seemed so naive he also seemed to think that <UNK> could <UNK> through the <UNK> without a problem which tells me he wasn't paying attention when <UNK> related the <UNK> and problems he had <UNK> br br i found it very brave of the director the screenplay writer and both star <UNK> lovers to <UNK> the <UNK> <UNK> story to a modern troubled land and to make both lovers male let's be honest here very few people would have a problem if one of them had been a female young love wins all hearts but when people's <UNK> with their sexuality is added to the fact that incredibly these same people would rather have them hate each other then the conclusion is inevitable\n",
            " y=1, y_pred=0, g(x)(H)=0.973, f(x)=0.560\n",
            "\n",
            "<START> i've read one comment which <UNK> this film trash and a waste br br of time i think this person got their political <UNK> <UNK> a bit br br too much br br i just rented the new <UNK> <UNK> of both yellow and blue br br these films although hardly great have at least become of br br historical interest as to the so called <UNK> student br br political social movement of the late <UNK> br br i hadn't seen either picture and from their notorious reputation i br br was expecting some real porn there isn't any there is <UNK> br br nudity including the still <UNK> <UNK> male nudity <UNK> br br <UNK> 17 the <UNK> x in the u s but i wasn't expecting the films br br in your face <UNK> <UNK> message br br though it tends to the simplistic i thought it <UNK> made br br its points well both films <UNK> had me laughing out loud br br and the director's commentary made it clear there was plenty of br br parody in the film especially the supposedly <UNK> sex br br scenes the first such scene is very realistic the lead couple is br br clumsy inept funny and endearing in their first <UNK> scene br br the second which caused the most <UNK> has <UNK> br br <UNK> and <UNK> and the last is the end of an angry fight br br that is believable br br the extras include an <UNK> introduction to the film an br br interview with the original american <UNK> and his attorney br br <UNK> from trial <UNK> in the u s and a <UNK> commentary br br by the director on some scenes br br this is the film that blue <UNK> wouldn't let alone and led to the br br <UNK> <UNK> interest with no social redeeming value standard br br that thankfully still stands br br those with an interest in the <UNK> of history will find this a must br br see\n",
            " y=1, y_pred=0, g(x)(H)=0.989, f(x)=0.576\n",
            "\n",
            "<START> i wanted to read the other comments before leaving my review and the majority <UNK> rules this movie is <UNK> from the acting to the non realistic animation to the countless errors i was actually hoping that the <UNK> would have been extended by a stretch of the imagination can't <UNK> <UNK> without <UNK> the <UNK> <UNK> cannot be <UNK> unless you have <UNK> that tiny little fan that was going was not <UNK> by any stretch to lower the <UNK> <UNK> the one thing i thought was quite <UNK> is when they <UNK> the back <UNK> touched down and then the nose one broke off thus <UNK> the plane with both back <UNK> in the air how did the captain <UNK> left and right <UNK> to <UNK> that weren't touching the ground did they forget the spoilers word to the director find out all you can about <UNK> before attempting a plane movie sorry for the technical <UNK> but i give this movie 1 10\n",
            " y=0, y_pred=1, g(x)(H)=0.995, f(x)=0.672\n",
            "\n",
            "\n",
            "Top misclassfied instances picked by g(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "<START> this had to be one of the most god awful <UNK> ever and is only saved by 2 matches the hardcore match between edge and <UNK> <UNK> also <UNK> <UNK> against <UNK> <UNK> the main event between <UNK> and <UNK> h was a complete <UNK> and to be honest i nearly fell asleep it was so <UNK> the <UNK> match was not worthy of having the <UNK> appear in it and the match between the <UNK> man and <UNK> t was a complete joke if you are really a big fan of the <UNK> and have missed the early days of the <UNK> and the <UNK> 17 and <UNK> you'll probably love this but i found that this <UNK> left a lot to be desired\n",
            " y=0, y_pred=1, g(x)(H)=1.000, f(x)=0.419\n",
            "<START> there are so many good things to say about this <UNK> movie br br <UNK> maybe in <UNK> but not in <UNK> this is about the best of its genre that i have ever seen a grade a effort by universal the script is well done imaginative and without fault writing credits howard <UNK> original story douglas <UNK> story john <UNK> screenplay director <UNK> <UNK> handled the complex story and story locations very well no <UNK> on the loads of extras and locations i loved <UNK> <UNK> jimmy <UNK> mother in <UNK> a wonderful <UNK> the <UNK> lead <UNK> <UNK> is a beauty and handled her part with grace and <UNK> for her karloff husband lugosi likewise was <UNK> <UNK> i think this is the best part i remember seeing him in as i said there were so many good things the african discovery of the <UNK> <UNK> the melting of the stone <UNK> somewhat reminiscent of the ten little indians in and then there were none <UNK> <UNK> the barry <UNK> version the <UNK> of <UNK> in the dark <UNK> mother played by <UNK> <UNK> cooper with <UNK> and because of all these <UNK> i found myself believing in the science it portrayed i guess <UNK> the mark of a good piece of art\n",
            " y=1, y_pred=0, g(x)(H)=0.999, f(x)=0.072\n",
            "<START> this movie is good for tv i like it because i'm a huge fan of disaster films even though this is a family film <UNK> on the film from the book is half and half they got the characters names right but in the book there was no storm <UNK> the the car scene involving the <UNK> family running away from the <UNK> wasn't in the book instead it involved dan <UNK> and his friend riding with a police officer on their way to the police station for safety and in the book dan and his friend are both 12 years old thats all i can think of overall this was a good movie even though it could of have been a little more accurate to the book did you know the book was based on a true story of a series of <UNK> <UNK> a small <UNK> town in 1980\n",
            " y=1, y_pred=0, g(x)(H)=1.000, f(x)=0.090\n",
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=27(eta=0.462), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "\n",
            "<START> i saw this little <UNK> gem two days after seeing <UNK> <UNK> make no mistake about it <UNK> is a <UNK> <UNK> ride be it american or european <UNK> <UNK> <UNK> or as it is being called in the u s <UNK> <UNK> is a tale of a young 15 year old girl played by <UNK> <UNK> who at times resembles a young <UNK> <UNK> acts the cool <UNK> girl who wants to be on the school <UNK> team just to be close to another attractive girl <UNK> <UNK> it's more than obvious that marie is more than attracted to <UNK> <UNK> among all of this is <UNK> rather <UNK> <UNK> friend anne who just wants a boyfriend like any other girl her age along the way we are shown the usual <UNK> of teen <UNK> broken hearts shop <UNK> <UNK> and or drug use <UNK> sex etc this is a quiet little film that takes time to work it's way into your system michael bay fans take note the pacing here is s l o w so <UNK> clear but if you have no problem with this water <UNK> is a <UNK> no rating here but would pull down a hard r due to language nudity adult situations\n",
            " y=1, y_pred=0, g(x)(H)=0.745, f(x)=0.556\n",
            "\n",
            "<START> the reviewer who called this movie a <UNK> has clearly missed the point it's obvious he hasn't been young or innocent in a very long time or he might have understood that the tragedy of it was that the well meaning young characters actually thought they could make a difference by putting up <UNK> and holding a <UNK> for peace if only it was that easy but the <UNK> sit and <UNK> at people who <UNK> try their best to make things better as the situation gets worse and worse every single day well if you're not part of the solution you're part of the problem br br the central theme is that revenge <UNK> more revenge which <UNK> even more in an ever <UNK> <UNK> both sides will tell you tales of <UNK> committed by the other side which they think justify their <UNK> even more in <UNK> where does it end and apparently he missed the <UNK> of the <UNK> <UNK> to in the name which was that people living in <UNK> <UNK> are strangely cut off from the ugly <UNK> of what is going on all around them which is partly why they seemed so naive he also seemed to think that <UNK> could <UNK> through the <UNK> without a problem which tells me he wasn't paying attention when <UNK> related the <UNK> and problems he had <UNK> br br i found it very brave of the director the screenplay writer and both star <UNK> lovers to <UNK> the <UNK> <UNK> story to a modern troubled land and to make both lovers male let's be honest here very few people would have a problem if one of them had been a female young love wins all hearts but when people's <UNK> with their sexuality is added to the fact that incredibly these same people would rather have them hate each other then the conclusion is inevitable\n",
            " y=1, y_pred=0, g(x)(H)=0.973, f(x)=0.560\n",
            "\n",
            "<START> i've read one comment which <UNK> this film trash and a waste br br of time i think this person got their political <UNK> <UNK> a bit br br too much br br i just rented the new <UNK> <UNK> of both yellow and blue br br these films although hardly great have at least become of br br historical interest as to the so called <UNK> student br br political social movement of the late <UNK> br br i hadn't seen either picture and from their notorious reputation i br br was expecting some real porn there isn't any there is <UNK> br br nudity including the still <UNK> <UNK> male nudity <UNK> br br <UNK> 17 the <UNK> x in the u s but i wasn't expecting the films br br in your face <UNK> <UNK> message br br though it tends to the simplistic i thought it <UNK> made br br its points well both films <UNK> had me laughing out loud br br and the director's commentary made it clear there was plenty of br br parody in the film especially the supposedly <UNK> sex br br scenes the first such scene is very realistic the lead couple is br br clumsy inept funny and endearing in their first <UNK> scene br br the second which caused the most <UNK> has <UNK> br br <UNK> and <UNK> and the last is the end of an angry fight br br that is believable br br the extras include an <UNK> introduction to the film an br br interview with the original american <UNK> and his attorney br br <UNK> from trial <UNK> in the u s and a <UNK> commentary br br by the director on some scenes br br this is the film that blue <UNK> wouldn't let alone and led to the br br <UNK> <UNK> interest with no social redeeming value standard br br that thankfully still stands br br those with an interest in the <UNK> of history will find this a must br br see\n",
            " y=1, y_pred=0, g(x)(H)=0.989, f(x)=0.576\n",
            "\n",
            "<START> i wanted to read the other comments before leaving my review and the majority <UNK> rules this movie is <UNK> from the acting to the non realistic animation to the countless errors i was actually hoping that the <UNK> would have been extended by a stretch of the imagination can't <UNK> <UNK> without <UNK> the <UNK> <UNK> cannot be <UNK> unless you have <UNK> that tiny little fan that was going was not <UNK> by any stretch to lower the <UNK> <UNK> the one thing i thought was quite <UNK> is when they <UNK> the back <UNK> touched down and then the nose one broke off thus <UNK> the plane with both back <UNK> in the air how did the captain <UNK> left and right <UNK> to <UNK> that weren't touching the ground did they forget the spoilers word to the director find out all you can about <UNK> before attempting a plane movie sorry for the technical <UNK> but i give this movie 1 10\n",
            " y=0, y_pred=1, g(x)(H)=0.995, f(x)=0.672\n",
            "\n",
            "\n",
            "Top misclassfied instances picked by g(x)\n",
            "-----------------------------------------\n",
            "<START> this movie set out to be better than the average action movie and in that regard they succeeded this movie had spectacular cinematography featuring spectacular mountain snow and <UNK> a very fit <UNK> putting in a good performance as well an exciting plot and a great performance from it's main villain <UNK> he will really shock you with his evil ways the movie does not rank an all time great <UNK> of the weak screen play the plot and story <UNK> for this movie to make <UNK> an extra special human much like the rambo or rocky or bond movie characters they chose to <UNK> <UNK> character in this one which is ok but considering the <UNK> style <UNK> the excitement factor also the dialogue was cheesy and <UNK> <UNK> at times the script should have been more realistic and less <UNK> another weak point was the unrealistic shooting scenes the movie makers should have been more <UNK> how they <UNK> the shooting hits and misses they should have continued the quality of the scenes of the shooting sequences during the plane <UNK> early in the movie instead they decided to water down a lot of the shooting sequences <UNK> a team tv series as soon as the villains set foot on the mountain <UNK> this movie had a lot of all time great potential <UNK> action sequences better dialogue and more rambo rocky style emotion <UNK> from <UNK> would have taken this movie to a higher level i know this was not <UNK> fault i sense the movie's director wanted to tone down <UNK> character and try to steal the movie by taking credit for his direction which was not all that great if not for his cinematographer <UNK> a good movie though\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.529\n",
            "\n",
            "<START> this had to be one of the most god awful <UNK> ever and is only saved by 2 matches the hardcore match between edge and <UNK> <UNK> also <UNK> <UNK> against <UNK> <UNK> the main event between <UNK> and <UNK> h was a complete <UNK> and to be honest i nearly fell asleep it was so <UNK> the <UNK> match was not worthy of having the <UNK> appear in it and the match between the <UNK> man and <UNK> t was a complete joke if you are really a big fan of the <UNK> and have missed the early days of the <UNK> and the <UNK> 17 and <UNK> you'll probably love this but i found that this <UNK> left a lot to be desired\n",
            " y=0, y_pred=1, g(x)(H)=1.000, f(x)=0.419\n",
            "\n",
            "<START> there are so many good things to say about this <UNK> movie br br <UNK> maybe in <UNK> but not in <UNK> this is about the best of its genre that i have ever seen a grade a effort by universal the script is well done imaginative and without fault writing credits howard <UNK> original story douglas <UNK> story john <UNK> screenplay director <UNK> <UNK> handled the complex story and story locations very well no <UNK> on the loads of extras and locations i loved <UNK> <UNK> jimmy <UNK> mother in <UNK> a wonderful <UNK> the <UNK> lead <UNK> <UNK> is a beauty and handled her part with grace and <UNK> for her karloff husband lugosi likewise was <UNK> <UNK> i think this is the best part i remember seeing him in as i said there were so many good things the african discovery of the <UNK> <UNK> the melting of the stone <UNK> somewhat reminiscent of the ten little indians in and then there were none <UNK> <UNK> the barry <UNK> version the <UNK> of <UNK> in the dark <UNK> mother played by <UNK> <UNK> cooper with <UNK> and because of all these <UNK> i found myself believing in the science it portrayed i guess <UNK> the mark of a good piece of art\n",
            " y=1, y_pred=0, g(x)(H)=0.999, f(x)=0.072\n",
            "\n",
            "<START> this movie is good for tv i like it because i'm a huge fan of disaster films even though this is a family film <UNK> on the film from the book is half and half they got the characters names right but in the book there was no storm <UNK> the the car scene involving the <UNK> family running away from the <UNK> wasn't in the book instead it involved dan <UNK> and his friend riding with a police officer on their way to the police station for safety and in the book dan and his friend are both 12 years old thats all i can think of overall this was a good movie even though it could of have been a little more accurate to the book did you know the book was based on a true story of a series of <UNK> <UNK> a small <UNK> town in 1980\n",
            " y=1, y_pred=0, g(x)(H)=1.000, f(x)=0.090\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-thpd8rmTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_txt = \"drive/My Drive/NIPS2020/results/imdb/instances_{clf}_yhat{yhat}_pca{pca}.txt\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "txt = open(path_txt, \"w\") \n",
        "txt.writelines(output_text.getvalue()) \n",
        "txt.close() #to change file access modes"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX7WuJijg-Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_table_concat = pd.concat(report_table)\n",
        "table_by_row_index = report_table_concat.groupby(report_table_concat.index)\n",
        "report_table_mean = table_by_row_index.mean()\n",
        "report_table_std = table_by_row_index.std()\n",
        "\n",
        "report_criteria_concat = pd.concat(report_criteria)\n",
        "table_by_row_index = report_criteria_concat.groupby(report_criteria_concat.index)\n",
        "report_criteria_mean = table_by_row_index.mean()\n",
        "report_criteria_std = table_by_row_index.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zDE3LuFiAvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8561aab0-af6f-4211-d048-a2abb77bf548"
      },
      "source": [
        "report_table_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.14192</td>\n",
              "      <td>3.786</td>\n",
              "      <td>0.820517</td>\n",
              "      <td>1.596467e-04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.1471</td>\n",
              "      <td>3.218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02472</td>\n",
              "      <td>0.12280</td>\n",
              "      <td>16.776</td>\n",
              "      <td>0.672585</td>\n",
              "      <td>1.438608e-20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.1273</td>\n",
              "      <td>16.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.84</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.10184</td>\n",
              "      <td>31.026</td>\n",
              "      <td>0.448278</td>\n",
              "      <td>2.111505e-39</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0457</td>\n",
              "      <td>0.1063</td>\n",
              "      <td>30.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.26</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06064</td>\n",
              "      <td>0.08688</td>\n",
              "      <td>41.244</td>\n",
              "      <td>0.423398</td>\n",
              "      <td>1.133743e-41</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.0634</td>\n",
              "      <td>0.0886</td>\n",
              "      <td>41.738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>50.104</td>\n",
              "      <td>0.136592</td>\n",
              "      <td>5.266706e-43</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0745</td>\n",
              "      <td>50.980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rule  rho_user  error_val  ...  error_test  L_test  %reduction_test\n",
              "0  1.06      0.01    0.00560  ...      0.0049  0.1471            3.218\n",
              "1  1.20      0.05    0.02472  ...      0.0247  0.1273           16.284\n",
              "2  0.84      0.10    0.04568  ...      0.0457  0.1063           30.058\n",
              "3  1.26      0.15    0.06064  ...      0.0634  0.0886           41.738\n",
              "4  0.12      0.20    0.07376  ...      0.0775  0.0745           50.980\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zgyJyu4iCBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cb39105f-bc61-49e2-e1ff-25a644cd23fe"
      },
      "source": [
        "report_criteria_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00488</td>\n",
              "      <td>0.14264</td>\n",
              "      <td>3.306</td>\n",
              "      <td>0.998604</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>3.672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02320</td>\n",
              "      <td>0.12432</td>\n",
              "      <td>15.728</td>\n",
              "      <td>0.964553</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0242</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>15.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04408</td>\n",
              "      <td>0.10344</td>\n",
              "      <td>29.916</td>\n",
              "      <td>0.885287</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0452</td>\n",
              "      <td>0.1068</td>\n",
              "      <td>29.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06088</td>\n",
              "      <td>0.08664</td>\n",
              "      <td>41.324</td>\n",
              "      <td>0.774637</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>0.0866</td>\n",
              "      <td>43.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07608</td>\n",
              "      <td>0.07144</td>\n",
              "      <td>51.648</td>\n",
              "      <td>0.668580</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>54.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val    L_val  ...  error_test  L_test  %reduction_test\n",
              "0      0.01    0.00488  0.14264  ...      0.0057  0.1463            3.672\n",
              "1      0.05    0.02320  0.12432  ...      0.0242  0.1278           15.878\n",
              "2      0.10    0.04408  0.10344  ...      0.0452  0.1068           29.700\n",
              "3      0.15    0.06088  0.08664  ...      0.0654  0.0866           43.020\n",
              "4      0.20    0.07608  0.07144  ...      0.0825  0.0695           54.300\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neU88XQkAzny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b792c43-3fdb-48ee-d89a-e251ef90f666"
      },
      "source": [
        "report_table_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.176010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>0.007034</td>\n",
              "      <td>0.797076</td>\n",
              "      <td>0.219716</td>\n",
              "      <td>3.569270e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.009283</td>\n",
              "      <td>1.190869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.104536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.007595</td>\n",
              "      <td>2.114800</td>\n",
              "      <td>0.264298</td>\n",
              "      <td>3.187349e-20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.009425</td>\n",
              "      <td>1.828026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.221884</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002918</td>\n",
              "      <td>0.007857</td>\n",
              "      <td>2.533146</td>\n",
              "      <td>0.322871</td>\n",
              "      <td>4.721467e-39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.006535</td>\n",
              "      <td>0.008526</td>\n",
              "      <td>3.697022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.047855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.010188</td>\n",
              "      <td>4.406856</td>\n",
              "      <td>0.203426</td>\n",
              "      <td>2.432024e-41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>0.008569</td>\n",
              "      <td>3.804684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.009045</td>\n",
              "      <td>4.302619</td>\n",
              "      <td>0.043197</td>\n",
              "      <td>1.177661e-42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.010186</td>\n",
              "      <td>0.009670</td>\n",
              "      <td>5.632673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rule  rho_user  error_val  ...  error_test    L_test  %reduction_test\n",
              "0  1.176010       0.0   0.001265  ...    0.001817  0.009283         1.190869\n",
              "1  1.104536       0.0   0.003025  ...    0.002564  0.009425         1.828026\n",
              "2  1.221884       0.0   0.002918  ...    0.006535  0.008526         3.697022\n",
              "3  1.047855       0.0   0.004495  ...    0.006628  0.008569         3.804684\n",
              "4  0.178885       0.0   0.005127  ...    0.010186  0.009670         5.632673\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjaMD-kKNMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "95ed1e63-79df-4e52-e414-e7a7d519ef96"
      },
      "source": [
        "report_criteria_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.007357</td>\n",
              "      <td>0.659454</td>\n",
              "      <td>0.000779</td>\n",
              "      <td>0.004472</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>0.007032</td>\n",
              "      <td>1.738094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>1.788413</td>\n",
              "      <td>0.016886</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.003347</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>1.419972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002834</td>\n",
              "      <td>0.007164</td>\n",
              "      <td>2.081797</td>\n",
              "      <td>0.053454</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005251</td>\n",
              "      <td>0.006496</td>\n",
              "      <td>2.410187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.007785</td>\n",
              "      <td>3.379797</td>\n",
              "      <td>0.081735</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005067</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>1.744506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005370</td>\n",
              "      <td>0.008341</td>\n",
              "      <td>4.106479</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006225</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>2.760860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val     L_val  ...  error_test    L_test  %reduction_test\n",
              "0       0.0   0.000996  0.007357  ...    0.003054  0.007032         1.738094\n",
              "1       0.0   0.002871  0.006832  ...    0.003347  0.007023         1.419972\n",
              "2       0.0   0.002834  0.007164  ...    0.005251  0.006496         2.410187\n",
              "3       0.0   0.004625  0.007785  ...    0.005067  0.005878         1.744506\n",
              "4       0.0   0.005370  0.008341  ...    0.006225  0.006567         2.760860\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NU73I2FKP6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}