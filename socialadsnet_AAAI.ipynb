{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRCkuTVcGMHA",
    "outputId": "84bcd814-8c83-4991-c458-1c30c2f12f7f"
   },
   "source": [
    "# Social Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqKVCUlTk4jf",
    "outputId": "507eeccb-bec2-48b0-b310-74bc0f68124f"
   },
   "outputs": [],
   "source": [
    "#! git clone https://github.com/cesar-claros/synergistic\n",
    "#% cd synergistic/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ml6Vk437FAHd"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Command line instalation\n",
    "# ---------------------------\n",
    "#! pip install torch\n",
    "#! pip install gpytorch\n",
    "\n",
    "# Imports\n",
    "# ---------------------------\n",
    "import io #Used as buffer\n",
    "import sys\n",
    "import matplotlib\n",
    "# matplotlib.use('qt5Agg')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import auxfunc.funcs as sgn\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from scipy.stats import entropy, spearmanr\n",
    "from sklearn import model_selection, svm, ensemble, linear_model, pipeline, decomposition,\\\n",
    "     tree, neighbors, discriminant_analysis, gaussian_process, preprocessing\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n",
    "plt.style.use(['ggplot','style/style.mplstyle'])\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Trust Score request\n",
    "# ---------------------------\n",
    "import urllib.request\n",
    "ts_code  = 'https://raw.githubusercontent.com/google/TrustScore/master/trustscore.py'\n",
    "ts_req   = urllib.request.urlopen(ts_code)\n",
    "read_req = ts_req.read()\n",
    "exec(read_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NWoZGvD-QNwr"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# MODELS\n",
    "# ====================\n",
    "# Grid search for parameters and classifiers\n",
    "\n",
    "models = { \n",
    "        'predictor':\n",
    "            [\n",
    "            svm.SVC(),\n",
    "            gaussian_process.GaussianProcessClassifier(),\n",
    "            linear_model.LinearRegression(),\n",
    "            linear_model.Lasso(),\n",
    "            svm.SVR()],\n",
    "        'name':\n",
    "            [\n",
    "            'SVM',\n",
    "            'GPClassifier',\n",
    "            'LinReg',\n",
    "            'Lasso',\n",
    "            'SVR']}\n",
    "parameters = [\n",
    "            {'SVM__kernel':['poly'],'SVM__degree':[3,4,5]},\n",
    "            {'GPClassifier__kernel':[]},\n",
    "            {},\n",
    "            {'Lasso__alpha':np.linspace(0.01,1,10)},\n",
    "            {'SVR__kernel':['linear'], 'SVR__C':np.logspace(-1, 1, 10), 'SVR__epsilon':np.logspace(-2, 2, 10)} ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P5kgx4mqidzz"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Signaling function fitting and evaluation\n",
    "def signalingFunction(X_train, y_train, y_train_pred_th, X_val, y_val, y_val_pred_th, X_test, y_test, y_test_pred_th, kernel='exponential', norm='l01'):\n",
    "    # X_train, X_val should be scaled\n",
    "    # Fit signaling function \n",
    "    exp = sgn.signaling(norm=norm) # idx = [train,test,val]\n",
    "    exp.fit(X_train, y_train, y_train_pred_th, kernel=kernel, n_iter=500, lr=0.01)\n",
    "    table_val = exp.evaluate(X_val, y_val, y_val_pred_th, rule_grid=np.linspace(0,3,30, endpoint=False), rho_grid=[0.1, 0.15])\n",
    "    table_test = exp.test(X_test, y_test, y_test_pred_th, table_val['rule'].to_numpy(), table_val['eta'].to_numpy())\n",
    "    table = pd.concat([table_val,table_test],axis=1)\n",
    "    return table, exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T_2y7G-HiujE"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Initialize model\n",
    "def init_model(input_dim, models, parameters, clf):\n",
    "    \n",
    "    if clf=='svm':\n",
    "      i = 0\n",
    "    elif clf=='gpc':\n",
    "      i = 1\n",
    "      kernel = 1.0 * RBF(length_scale=1.0*np.ones(input_dim)) \n",
    "      parameters[i]['GPClassifier__kernel'].append(kernel)\n",
    "      \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    steps = [('scaler', scaler), (models['name'][i], models['predictor'][i])]\n",
    "    ppline = pipeline.Pipeline(steps) # define the pipeline object.\n",
    "\n",
    "    clf = model_selection.GridSearchCV(ppline, param_grid=parameters[i], cv=5)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rYgvy9cRs1m1"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Soft and thresholded output predictions\n",
    "def pred_output(model, X):\n",
    "    if hasattr(model, \"decision_function\"):\n",
    "      y_pred_soft = model.best_estimator_.decision_function(X)[:,None]\n",
    "      y_pred_th = model.best_estimator_.predict(X)\n",
    "    else:\n",
    "      y_pred_soft = model.best_estimator_.predict_proba(X)\n",
    "      y_pred_th = model.best_estimator_.predict(X)\n",
    "    return y_pred_soft, y_pred_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZPco9Y0aHUpL"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Jaccard similarity index\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dHrKyMLGq_Is"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Baseline comparison\n",
    "def baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf,trust_val,trust_test):\n",
    "      if clf=='svm':\n",
    "          direction = 'closer'\n",
    "          crit_val  = np.abs(y_val_pred_soft.ravel())\n",
    "          crit_test = np.abs(y_test_pred_soft.ravel())\n",
    "      else:\n",
    "          direction = 'further'\n",
    "          p_val = np.concatenate((y_val_pred_soft,1-y_val_pred_soft),axis=1)\n",
    "          crit_val  = entropy(p_val, axis=1, base=2)\n",
    "          p_test    = np.concatenate((y_test_pred_soft,1-y_test_pred_soft),axis=1)\n",
    "          crit_test = entropy(p_test, axis=1, base=2)\n",
    "      # Criteria 1\n",
    "      critFunc   = sgn.critEvaluation(norm='l01',direction=direction)\n",
    "      d_val      = critFunc.evaluate(y_val, y_val_pred_th, crit_val, rho_grid=[0.1, 0.15])\n",
    "      d_test     = critFunc.test(y_test, y_test_pred_th, crit_test, d_val['thresh'].to_numpy())\n",
    "      crit_table = pd.concat([d_val,d_test],axis=1)   \n",
    "      # Best rules from signailing function on val are used to get UCBs on test\n",
    "      gamma      = table['rule'].to_numpy().reshape(-1,1)\n",
    "      f_test     = exp.gpr_mean_test + gamma*np.sqrt(exp.gpr_var_test)\n",
    "      # Threshold values on val data. UCB Signailing (eta) and new criteria (theta) \n",
    "      eta        = table['eta'].to_numpy().reshape(-1,1)\n",
    "      theta      = crit_table['thresh'].to_numpy().reshape(-1,1)        \n",
    "      if direction == 'closer':\n",
    "        crit_mask, crit_idx = np.nonzero(crit_test.reshape(1,-1)<theta)\n",
    "      else:\n",
    "        crit_mask, crit_idx = np.nonzero(crit_test.reshape(1,-1)>theta)\n",
    "      f_mask, f_idx = np.nonzero(f_test>eta)\n",
    "      shared = set(list(np.unique(f_mask))).intersection(set(list(np.unique(crit_mask))))\n",
    "      # Jaccard index btw signaled instances using both methods for ith rule-threshold\n",
    "      J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan for i in range(f_test.shape[0])]            \n",
    "      crit_table['jaccard']=J\n",
    "      Sp = [spearmanr(f_test[i,:],crit_test)[0] for i in range(f_test.shape[0])]\n",
    "      crit_table['spearman'] = Sp\n",
    "      crit_table['gamma'] = gamma\n",
    "        \n",
    "      # Criteria 2\n",
    "      critFuncSc = sgn.critEvaluation(norm='l01',direction='closer')\n",
    "      s_val      = critFuncSc.evaluate(y_val, y_val_pred_th, trust_val, rho_grid=[0.1, 0.15])\n",
    "      s_test     = critFuncSc.test(y_test, y_test_pred_th, trust_test, s_val['thresh'].to_numpy())\n",
    "      score_table= pd.concat([s_val,s_test],axis=1)\n",
    "      # Threshold values on val data. TrustScore (theta0) \n",
    "      theta0     = score_table['thresh'].to_numpy().reshape(-1,1) \n",
    "      crit_mask0, crit_idx0 = np.nonzero(trust_test.reshape(1,-1)<theta0)\n",
    "      # Jaccard index btw signaled instances using both methods for ith rule-threshold  \n",
    "      shared0    = set(list(np.unique(f_mask))).intersection(set(list(np.unique(crit_mask0))))\n",
    "      J0         = [jaccard_similarity(crit_idx0[crit_mask0==i],f_idx[f_mask==i]) if i in shared0 else np.nan for i in range(f_test.shape[0])]\n",
    "      Sp0        = [spearmanr(f_test[i,:],trust_test)[0] for i in range(f_test.shape[0])]\n",
    "      score_table['jaccard']  = J0 \n",
    "      score_table['spearman'] = Sp0      \n",
    "      return crit_table,score_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Trust score adaptation for python3 (xrange)\n",
    "class trust_score(TrustScore):\n",
    "    def __init__(self,k=10, alpha=0., filtering=\"none\", min_dist=1e-12):\n",
    "        super().__init__(k,alpha,filtering,min_dist)\n",
    "    def fit(self, X, y):\n",
    "      \"\"\"Initialize trust score precomputations with training data.\n",
    "      WARNING: assumes that the labels are 0-indexed (i.e.\n",
    "      0, 1,..., n_labels-1).\n",
    "      Args:\n",
    "      X: an array of sample points.\n",
    "      y: corresponding labels.\n",
    "      \"\"\"\n",
    "      self.n_labels = np.max(y) + 1\n",
    "      self.kdtrees = [None] * self.n_labels\n",
    "      if self.filtering == \"uncertainty\":\n",
    "        X_filtered, y_filtered = self.filter_by_uncertainty(X, y)\n",
    "      for label in range(self.n_labels):\n",
    "        if self.filtering == \"none\":\n",
    "          X_to_use = X[np.where(y == label)[0]]\n",
    "          self.kdtrees[label] = KDTree(X_to_use)\n",
    "        elif self.filtering == \"density\":\n",
    "          X_to_use = self.filter_by_density(X[np.where(y == label)[0]])\n",
    "          self.kdtrees[label] = KDTree(X_to_use)\n",
    "        elif self.filtering == \"uncertainty\":\n",
    "          X_to_use = X_filtered[np.where(y_filtered == label)[0]]\n",
    "          self.kdtrees[label] = KDTree(X_to_use)\n",
    "\n",
    "        if len(X_to_use) == 0:\n",
    "          print(\"Filtered too much or missing examples from a label! Please lower alpha or check data.\")\n",
    "\n",
    "    def get_score(self, X, y_pred):\n",
    "      \"\"\"Compute the trust scores.\n",
    "      Given a set of points, determines the distance to each class.\n",
    "      Args:\n",
    "      X: an array of sample points.\n",
    "      y_pred: The predicted labels for these points.\n",
    "      Returns:\n",
    "      The trust score, which is ratio of distance to closest class that was not\n",
    "      the predicted class to the distance to the predicted class.\n",
    "      \"\"\"\n",
    "      d = np.tile(None, (X.shape[0], self.n_labels))\n",
    "      for label_idx in range(self.n_labels):\n",
    "        d[:, label_idx] = self.kdtrees[label_idx].query(X, k=2)[0][:, -1]\n",
    "\n",
    "      sorted_d = np.sort(d, axis=1)\n",
    "      d_to_pred = d[range(d.shape[0]), y_pred]\n",
    "      d_to_closest_not_pred = np.where(sorted_d[:, 0] != d_to_pred,\n",
    "                                      sorted_d[:, 0], sorted_d[:, 1])\n",
    "      return d_to_closest_not_pred / (d_to_pred + self.min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signailing function & baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Load data\n",
    "# ---------------------------\n",
    "df = pd.read_table('datasets/Social_Network_Ads.csv')\n",
    "Data_X = df.iloc[:,[2,3]]\n",
    "Data_y = df.iloc[:,4]\n",
    "Data_X = Data_X.to_numpy()\n",
    "Data_y = Data_y.to_numpy()\n",
    "\n",
    "# Seed definition for reproducibility\n",
    "# ---------------------------\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "SEED = 123\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRWPIuqwRLoD",
    "outputId": "5148d064-96ba-496f-ae90-22deb8aaf48d"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# Cross validation setup\n",
    "# ---------------------------\n",
    "report_table    = []\n",
    "report_criteria = []\n",
    "trust_criteria  = []\n",
    "addPredictions  = True\n",
    "clf      = 'gpc'\n",
    "accuracy = 0\n",
    "fold     = 1\n",
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "\n",
    "# ML model fit + Signailing function + Baseline comparison\n",
    "# ---------------------------\n",
    "for sample, test in kf.split(Data_X, Data_y):\n",
    "    X = Data_X[sample]\n",
    "    y = Data_y[sample]\n",
    "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.20, random_state=SEED)\n",
    "    X_test = Data_X[test]\n",
    "    y_test = Data_y[test]\n",
    "\n",
    "    # ML Model fit & prediction\n",
    "    model = init_model(input_dim=X.shape[1], models=models, parameters=parameters, clf=clf)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred_soft, y_train_pred_th = pred_output(model, X_train)\n",
    "    y_val_pred_soft  , y_val_pred_th   = pred_output(model, X_val)\n",
    "    y_test_pred_soft , y_test_pred_th  = pred_output(model, X_test)\n",
    "    print('accuracy(Train)={}'.format(np.sum(y_train==y_train_pred_th)/np.size(y_train)))\n",
    "    \n",
    "    # Signailing function. Design matrix\n",
    "    X_train_GP = X_train\n",
    "    X_val_GP   = X_val\n",
    "    X_test_GP  = X_test\n",
    "    if addPredictions:\n",
    "        X_train_GP = np.concatenate((X_train_GP, y_train_pred_soft), axis=1)\n",
    "        X_val_GP   = np.concatenate((X_val_GP, y_val_pred_soft), axis=1)\n",
    "        X_test_GP  = np.concatenate((X_test_GP, y_test_pred_soft), axis=1)\n",
    "    scaleX_GP  = preprocessing.StandardScaler().fit(X_train_GP)\n",
    "    X_train_GP = scaleX_GP.transform(X_train_GP)\n",
    "    X_val_GP   = scaleX_GP.transform(X_val_GP)\n",
    "    X_test_GP  = scaleX_GP.transform(X_test_GP)\n",
    "    \n",
    "    # Signailing function. Call\n",
    "    table, exp = signalingFunction(X_train_GP, y_train, y_train_pred_th, X_val_GP, y_val, y_val_pred_th, X_test_GP, y_test, y_test_pred_th)\n",
    "    report_table.append(pd.concat([pd.DataFrame({'fold':[fold]*table.shape[0]}),table],axis=1))\n",
    "\n",
    "    # Trust Score fitted on train data to evaluate loss reduction on val-test data\n",
    "    trust_model = trust_score()\n",
    "    trust_model.fit(X=X_train_GP,y=y_train)\n",
    "    trust_val  = trust_model.get_score(X_val_GP, y_val_pred_th)\n",
    "    trust_test = trust_model.get_score(X_test_GP, y_test_pred_th)\n",
    "    \n",
    "    # Baseline for comparison\n",
    "    crit_table,score_table = baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf, trust_val, trust_test)\n",
    "    report_criteria.append(pd.concat([pd.DataFrame({'fold':[fold]*crit_table.shape[0]}),crit_table],axis=1))\n",
    "    trust_criteria.append(pd.concat([pd.DataFrame({'fold':[fold]*score_table.shape[0]}),score_table],axis=1))\n",
    "\n",
    "    if accuracy < model.best_estimator_.score(X_val,y_val):\n",
    "        accuracy = model.best_estimator_.score(X_val,y_val)\n",
    "        classifier = model.best_estimator_\n",
    "        X_test_surface_plot = X_test\n",
    "        y_test_surface_plot = y_test\n",
    "        X_train_surface_plot = X_train\n",
    "        y_train_surface_plot = y_train\n",
    "        X_val_surface_plot = X_val\n",
    "        y_val_surface_plot = y_val\n",
    "        scaler_surface_plot = scaleX_GP\n",
    "        exp_surface_plot = exp\n",
    "        table_surface_plot = table\n",
    "    fold +=1\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rho_user</th>\n",
       "      <th>rule</th>\n",
       "      <th>corrected_val</th>\n",
       "      <th>queries_val</th>\n",
       "      <th>total_wrong_val</th>\n",
       "      <th>loss_query_val</th>\n",
       "      <th>rho_hat_val</th>\n",
       "      <th>%loss_red_val</th>\n",
       "      <th>eta</th>\n",
       "      <th>p_value</th>\n",
       "      <th>corrected_test</th>\n",
       "      <th>queries_test</th>\n",
       "      <th>total_wrong_test</th>\n",
       "      <th>loss_query_test</th>\n",
       "      <th>rho_hat_test</th>\n",
       "      <th>%loss_red_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.249682</td>\n",
       "      <td>0.269006</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "      <td>40.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.171871</td>\n",
       "      <td>0.431673</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>50.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.09</td>\n",
       "      <td>27.27</td>\n",
       "      <td>0.258228</td>\n",
       "      <td>0.013808</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.14</td>\n",
       "      <td>45.45</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.12</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.197382</td>\n",
       "      <td>0.269006</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.16</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>16.67</td>\n",
       "      <td>0.075075</td>\n",
       "      <td>0.431673</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>66.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.09</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.260077</td>\n",
       "      <td>0.142057</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>33.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0.169816</td>\n",
       "      <td>0.267048</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.22</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.271372</td>\n",
       "      <td>0.753838</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.11</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.241830</td>\n",
       "      <td>0.802906</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.15</td>\n",
       "      <td>60.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  rho_user  rule  corrected_val  queries_val  total_wrong_val  \\\n",
       "0     1      0.10   0.0            1.0            6              6.0   \n",
       "1     1      0.15   0.0            1.0            9              6.0   \n",
       "0     2      0.10   0.0            3.0            6             11.0   \n",
       "1     2      0.15   0.1            5.0            9             11.0   \n",
       "0     3      0.10   0.0            1.0            6              6.0   \n",
       "1     3      0.15   0.0            1.0            9              6.0   \n",
       "0     4      0.10   0.0            1.0            6              4.0   \n",
       "1     4      0.15   0.0            1.0            9              4.0   \n",
       "0     5      0.10   0.0            0.0            6              4.0   \n",
       "1     5      0.15   0.0            0.0            9              4.0   \n",
       "\n",
       "   loss_query_val  rho_hat_val  %loss_red_val       eta   p_value  \\\n",
       "0            0.17         0.09          16.67  0.249682  0.269006   \n",
       "1            0.11         0.14          16.67  0.171871  0.431673   \n",
       "0            0.50         0.09          27.27  0.258228  0.013808   \n",
       "1            0.56         0.14          45.45  0.247508  0.000576   \n",
       "0            0.17         0.09          16.67  0.197382  0.269006   \n",
       "1            0.11         0.14          16.67  0.075075  0.431673   \n",
       "0            0.17         0.09          25.00  0.260077  0.142057   \n",
       "1            0.11         0.14          25.00  0.169816  0.267048   \n",
       "0            0.00         0.09           0.00  0.271372  0.753838   \n",
       "1            0.00         0.14           0.00  0.241830  0.802906   \n",
       "\n",
       "   corrected_test  queries_test  total_wrong_test  loss_query_test  \\\n",
       "0             4.0            10              10.0             0.40   \n",
       "1             5.0            12              10.0             0.42   \n",
       "0             4.0             9               6.0             0.44   \n",
       "1             4.0            10               6.0             0.40   \n",
       "0             5.0            13               9.0             0.38   \n",
       "1             6.0            23               9.0             0.26   \n",
       "0             3.0            10               9.0             0.30   \n",
       "1             5.0            18               9.0             0.28   \n",
       "0             3.0             9               5.0             0.33   \n",
       "1             3.0            12               5.0             0.25   \n",
       "\n",
       "   rho_hat_test  %loss_red_test  \n",
       "0          0.12           40.00  \n",
       "1          0.15           50.00  \n",
       "0          0.11           66.67  \n",
       "1          0.12           66.67  \n",
       "0          0.16           55.56  \n",
       "1          0.29           66.67  \n",
       "0          0.12           33.33  \n",
       "1          0.22           55.56  \n",
       "0          0.11           60.00  \n",
       "1          0.15           60.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_table_concat = pd.concat(report_table)\n",
    "report_table_concat.sort_values(by=['fold','rho_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rho_user</th>\n",
       "      <th>corrected_val</th>\n",
       "      <th>queries_val</th>\n",
       "      <th>total_wrong_val</th>\n",
       "      <th>loss_query_val</th>\n",
       "      <th>rho_hat_val</th>\n",
       "      <th>%loss_red_val</th>\n",
       "      <th>thresh</th>\n",
       "      <th>corrected_test</th>\n",
       "      <th>queries_test</th>\n",
       "      <th>total_wrong_test</th>\n",
       "      <th>loss_query_test</th>\n",
       "      <th>rho_hat_test</th>\n",
       "      <th>%loss_red_test</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>spearman</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.838680</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.08</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.943710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.802707</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.943710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>27.27</td>\n",
       "      <td>1.829422</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.844183</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>45.45</td>\n",
       "      <td>1.778266</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865510</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.785725</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.15</td>\n",
       "      <td>55.56</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.786528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.687872</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.22</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.786528</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.860635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.09</td>\n",
       "      <td>44.44</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.776643</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.796995</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>44.44</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.776643</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.815566</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.639567</td>\n",
       "      <td>4.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.28</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.881944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  rho_user  corrected_val  queries_val  total_wrong_val  \\\n",
       "0     1      0.10            1.0            6              6.0   \n",
       "1     1      0.15            1.0            9              6.0   \n",
       "0     2      0.10            3.0            6             11.0   \n",
       "1     2      0.15            5.0            9             11.0   \n",
       "0     3      0.10            1.0            6              6.0   \n",
       "1     3      0.15            1.0            9              6.0   \n",
       "0     4      0.10            2.0            6              4.0   \n",
       "1     4      0.15            2.0            9              4.0   \n",
       "0     5      0.10            1.0            6              4.0   \n",
       "1     5      0.15            1.0            9              4.0   \n",
       "\n",
       "   loss_query_val  rho_hat_val  %loss_red_val    thresh  corrected_test  \\\n",
       "0            0.17     0.093750          16.67  1.838680             3.0   \n",
       "1            0.11     0.140625          16.67  1.802707             3.0   \n",
       "0            0.50     0.093750          27.27  1.829422             4.0   \n",
       "1            0.56     0.140625          45.45  1.778266             4.0   \n",
       "0            0.17     0.093750          16.67  1.785725             5.0   \n",
       "1            0.11     0.140625          16.67  1.687872             6.0   \n",
       "0            0.33     0.093750          50.00  1.860635             4.0   \n",
       "1            0.22     0.140625          50.00  1.796995             4.0   \n",
       "0            0.17     0.093750          25.00  1.815566             1.0   \n",
       "1            0.11     0.140625          25.00  1.639567             4.0   \n",
       "\n",
       "   queries_test  total_wrong_test  loss_query_test  rho_hat_test  \\\n",
       "0             6              10.0             0.50          0.08   \n",
       "1             7              10.0             0.43          0.09   \n",
       "0             9               6.0             0.44          0.11   \n",
       "1            11               6.0             0.36          0.14   \n",
       "0            12               9.0             0.42          0.15   \n",
       "1            18               9.0             0.33          0.22   \n",
       "0             7               9.0             0.57          0.09   \n",
       "1            13               9.0             0.31          0.16   \n",
       "0             7               5.0             0.14          0.09   \n",
       "1            22               5.0             0.18          0.28   \n",
       "\n",
       "   %loss_red_test   jaccard  spearman  gamma  \n",
       "0           30.00  0.600000  0.943710    0.0  \n",
       "1           30.00  0.461538  0.943710    0.0  \n",
       "0           66.67  0.636364  0.844183    0.0  \n",
       "1           66.67  0.750000  0.865510    0.1  \n",
       "0           55.56  0.666667  0.786528    0.0  \n",
       "1           66.67  0.464286  0.786528    0.0  \n",
       "0           44.44  0.416667  0.776643    0.0  \n",
       "1           44.44  0.550000  0.776643    0.0  \n",
       "0           20.00  0.333333  0.881944    0.0  \n",
       "1           80.00  0.360000  0.881944    0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_criteria_concat = pd.concat(report_criteria)\n",
    "report_criteria_concat.sort_values(by=['fold','rho_user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>rho_user</th>\n",
       "      <th>corrected_val</th>\n",
       "      <th>queries_val</th>\n",
       "      <th>total_wrong_val</th>\n",
       "      <th>loss_query_val</th>\n",
       "      <th>rho_hat_val</th>\n",
       "      <th>%loss_red_val</th>\n",
       "      <th>thresh</th>\n",
       "      <th>corrected_test</th>\n",
       "      <th>queries_test</th>\n",
       "      <th>total_wrong_test</th>\n",
       "      <th>loss_query_test</th>\n",
       "      <th>rho_hat_test</th>\n",
       "      <th>%loss_red_test</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.501108</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>-0.556193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>33.33</td>\n",
       "      <td>2.219297</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.18</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>-0.556193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>27.27</td>\n",
       "      <td>1.7317</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.11</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>-0.550482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>36.36</td>\n",
       "      <td>2.02298</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>66.67</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>-0.575373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>16.67</td>\n",
       "      <td>1.738069</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.16</td>\n",
       "      <td>44.44</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>-0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>16.67</td>\n",
       "      <td>2.136126</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>44.44</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>-0.657407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.434645</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.08</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.494055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.978568</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.18</td>\n",
       "      <td>44.44</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>-0.494055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>25.00</td>\n",
       "      <td>1.482466</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>-0.863730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>50.00</td>\n",
       "      <td>1.808942</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.14</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>-0.863730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  rho_user  corrected_val  queries_val  total_wrong_val  \\\n",
       "0     1      0.10            1.0            6              6.0   \n",
       "1     1      0.15            2.0            9              6.0   \n",
       "0     2      0.10            3.0            6             11.0   \n",
       "1     2      0.15            4.0            9             11.0   \n",
       "0     3      0.10            1.0            6              6.0   \n",
       "1     3      0.15            1.0            9              6.0   \n",
       "0     4      0.10            1.0            6              4.0   \n",
       "1     4      0.15            1.0            9              4.0   \n",
       "0     5      0.10            1.0            6              4.0   \n",
       "1     5      0.15            2.0            9              4.0   \n",
       "\n",
       "   loss_query_val  rho_hat_val  %loss_red_val    thresh  corrected_test  \\\n",
       "0            0.17     0.093750          16.67  1.501108             5.0   \n",
       "1            0.22     0.140625          33.33  2.219297             5.0   \n",
       "0            0.50     0.093750          27.27    1.7317             3.0   \n",
       "1            0.44     0.140625          36.36   2.02298             4.0   \n",
       "0            0.17     0.093750          16.67  1.738069             4.0   \n",
       "1            0.11     0.140625          16.67  2.136126             4.0   \n",
       "0            0.17     0.093750          25.00  1.434645             2.0   \n",
       "1            0.11     0.140625          25.00  1.978568             4.0   \n",
       "0            0.17     0.093750          25.00  1.482466             3.0   \n",
       "1            0.22     0.140625          50.00  1.808942             3.0   \n",
       "\n",
       "   queries_test  total_wrong_test  loss_query_test  rho_hat_test  \\\n",
       "0             9              10.0             0.56          0.11   \n",
       "1            14              10.0             0.36          0.18   \n",
       "0             9               6.0             0.33          0.11   \n",
       "1            13               6.0             0.31          0.16   \n",
       "0            13               9.0             0.31          0.16   \n",
       "1            14               9.0             0.29          0.18   \n",
       "0             6               9.0             0.33          0.08   \n",
       "1            14               9.0             0.29          0.18   \n",
       "0            10               5.0             0.30          0.12   \n",
       "1            11               5.0             0.27          0.14   \n",
       "\n",
       "   %loss_red_test   jaccard  spearman  \n",
       "0           50.00  0.357143 -0.556193  \n",
       "1           50.00  0.368421 -0.556193  \n",
       "0           50.00  0.384615 -0.550482  \n",
       "1           66.67  0.533333 -0.575373  \n",
       "0           44.44  0.529412 -0.657407  \n",
       "1           44.44  0.541667 -0.657407  \n",
       "0           22.22  0.333333 -0.494055  \n",
       "1           44.44  0.454545 -0.494055  \n",
       "0           60.00  0.583333 -0.863730  \n",
       "1           60.00  0.533333 -0.863730  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trust_criteria_concat = pd.concat(trust_criteria)\n",
    "trust_criteria_concat.sort_values(by=['fold','rho_user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt-get install texlive-latex-recommended #1\n",
    "! sudo apt-get install dvipng texlive-fonts-recommended #2\n",
    "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip #3\n",
    "! unzip type1cm.zip -d /tmp/type1cm #4\n",
    "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins  #5\n",
    "! sudo mkdir /usr/share/texmf/tex/latex/type1cm #6\n",
    "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm #7\n",
    "! sudo texhash #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "WCiI4764Haf8",
    "outputId": "47d07795-914b-4751-ed94-56514584652d"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(15, 5.1), constrained_layout=False, dpi=90)\n",
    "pal = sns.color_palette('Paired')\n",
    "sns.boxplot(x=df['rho_user'], y=df['%reduction_test'], hue='label', data=df, ax=ax[0], palette=pal)\n",
    "ax[0].set_xlabel(r'budget $\\rho$')\n",
    "ax[0].set_ylabel(r'Loss reduction $r_{test}(\\%)$')\n",
    "ax[0].legend(loc='upper left')\n",
    "pal = sns.color_palette('BuGn_r')\n",
    "sns.boxplot(x=df_jaccard['rho_user'], y=df_jaccard['jaccard'], data=df_jaccard, ax=ax[1], palette=pal)\n",
    "ax[1].set_xlabel(r'budget $\\rho$')\n",
    "ax[1].set_ylabel(r'Jaccard index $J$')\n",
    "plt.tight_layout()\n",
    "path_fig_fxgx = \"drive/My Drive/NIPS2020/results/socialadsnet/fig_fxgx_{clf}_yhat{yhat}_pca{pca}.pdf\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
    "plt.savefig(path_fig_fxgx, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "Rw8ao37-ymu6",
    "outputId": "ca822552-b639-4063-ab8a-f76104423c8e"
   },
   "outputs": [],
   "source": [
    "  #%%\n",
    "# PLOT DECISION SURFACE\n",
    "# ==================\n",
    "# Plot test instances and decision surface\n",
    "# ----------------------------------------------\n",
    "# Visualising the Train set results\n",
    "fig1 = plt.figure(figsize=(10,8),dpi=120)\n",
    "ax1 = fig1.add_subplot(111)\n",
    "X_set, y_set = X_train_surface_plot, y_train_surface_plot\n",
    "y_set[y_set==0] = -1\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d_set = 1-y_set*classifier.decision_function(X_set)\n",
    "else:\n",
    "    pred_x = classifier.predict(X_set)\n",
    "    pred_x[pred_x==0] = -1\n",
    "    d_set = y_set*pred_x\n",
    "xi_set = np.max([[np.zeros(d_set.size)],[d_set]],axis=0).ravel()\n",
    "\n",
    "aranged_ages = np.arange(start = X_set[:, 0].min()-5, stop = X_set[:, 0].max()+5, step = 0.025)\n",
    "aranged_salaries = np.arange(start = X_set[:, 1].min()-4000, stop = X_set[:, 1].max()+4000, step = 500)\n",
    "\n",
    "X1, X2 = np.meshgrid(aranged_ages, aranged_salaries)\n",
    "Z = classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape)\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d = classifier.decision_function(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape)\n",
    "    ax1.contourf(X1, X2, np.where((np.abs(d)<1),np.abs(d),np.nan), alpha = 0.6, cmap='gist_gray', label='margin region')\n",
    "    ax1.contour(X1, X2, d, levels=[-1, 0, 1], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set>1,0]\n",
    "    y = X_set[xi_set>1,1]\n",
    "else:\n",
    "    d = classifier.predict_proba(np.array([X1.ravel(), X2.ravel()]).T)[:, 1].reshape(X1.shape)-0.5\n",
    "    ax1.contourf(X1, X2, np.where((np.abs(d)<0.25),np.abs(d),np.nan), alpha = 0.6, cmap='gist_gray', label='margin region')\n",
    "    ax1.contour(X1, X2, d, levels=[-0.25, 0.0, 0.25], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set==0,0]\n",
    "    y = X_set[xi_set==0,1]\n",
    "dots = ['red','blue']\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                color = dots[i], label = '{}'.format('no purchase' if i==0 else 'purchase'),alpha=0.7, s=65, linewidths=5)\n",
    "# Plot slack variables magnitudes\n",
    "ax1.scatter(x, y, s=150, facecolors='none', edgecolors='g', label='misclassified', linewidths=5)\n",
    "\n",
    "ax1.set_xlabel('Age', fontsize=40)\n",
    "ax1.set_ylabel('Salary', fontsize=40)\n",
    "ax1.set_title('Training set', fontsize=40)\n",
    "ax1.legend(loc='lower left', framealpha=0.5, prop={'size': 30}, labelspacing=0.0)\n",
    "formatter0 = matplotlib.ticker.EngFormatter()\n",
    "ax1.yaxis.set_major_formatter(formatter0)\n",
    "X1_min, X1_max = X1.min(), X1.max()\n",
    "X2_min, X2_max = X2.min(), X2.max()\n",
    "ax1.set_xlim(X1_min, X1_max)\n",
    "ax1.set_ylim(X2_min, X2_max)\n",
    "plt.tight_layout()\n",
    "path_fig_fx_train = \"drive/My Drive/NIPS2020/results/socialadsnet/fig_fx_train_{clf}_yhat{yhat}_pca{pca}.svg\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
    "plt.savefig(path_fig_fx_train, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "DwpQgHNpA6zm",
    "outputId": "a547aef7-6823-4e4c-b1e6-f50f3c57d1f8"
   },
   "outputs": [],
   "source": [
    "#%%\n",
    "# PLOT DECISION SURFACE\n",
    "# ==================\n",
    "# Plot test instances and decision surface\n",
    "# ----------------------------------------------\n",
    "# Visualising the Train set results\n",
    "fig1 = plt.figure(figsize=(8,8),dpi=120)\n",
    "ax1 = fig1.add_subplot(111)\n",
    "X_set, y_set = X_val_surface_plot, y_val_surface_plot\n",
    "y_set[y_set==0] = -1\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d_set = 1-y_set*classifier.decision_function(X_set)\n",
    "else:\n",
    "    pred_x = classifier.predict(X_set)\n",
    "    pred_x[pred_x==0] = -1\n",
    "    d_set = y_set*pred_x\n",
    "xi_set = np.max([[np.zeros(d_set.size)],[d_set]],axis=0).ravel()\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d = classifier.decision_function(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape)\n",
    "    ax1.contourf(X1, X2, np.where((np.abs(d)<1),np.abs(d),np.nan), alpha = 0.6, cmap='gist_gray', label='margin region')\n",
    "    ax1.contour(X1, X2, d, levels=[-1,0,1], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set>1,0]\n",
    "    y = X_set[xi_set>1,1]\n",
    "else:\n",
    "    d = classifier.predict_proba(np.array([X1.ravel(), X2.ravel()]).T)[:, 1].reshape(X1.shape)-0.5\n",
    "    ax1.contourf(X1, X2, np.where((np.abs(d)<0.25),np.abs(d),np.nan), alpha = 0.6, cmap='gist_gray', label='margin region')\n",
    "    ax1.contour(X1, X2, d, levels=[-0.25, 0, 0.25], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set==0,0]\n",
    "    y = X_set[xi_set==0,1]\n",
    "\n",
    "dots = ['red','blue']\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                color = dots[i], label = '{}'.format('no purchase' if i==0 else 'purchase'),alpha=0.7,s=150, marker='*', linewidths=5)\n",
    "# Plot slack variables magnitudes\n",
    "ax1.scatter(x, y, s=150, facecolors='none', edgecolors='g', label='misclassified', linewidths=5)\n",
    " \n",
    "ax1.set_xlabel('Age',fontsize=40)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Validation set',fontsize=40)\n",
    "ax1.legend(loc='lower left', framealpha=0.5, prop={'size': 30},labelspacing=0.0)\n",
    "ax1.set_xlim(X1_min, X1_max)\n",
    "ax1.set_ylim(X2_min, X2_max)\n",
    "plt.tight_layout()\n",
    "path_fig_fx_val = \"drive/My Drive/NIPS2020/results/socialadsnet/fig_fx_val_{clf}_yhat{yhat}_pca{pca}.svg\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
    "plt.savefig(path_fig_fx_val, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 919
    },
    "id": "OMj3AeGfHm0J",
    "outputId": "3924a1d9-1fa5-420c-bfeb-8dd27e9f00f5"
   },
   "outputs": [],
   "source": [
    "t = np.stack((X1.ravel(), X2.ravel()), axis=1)\n",
    "t_scaled = scaler_surface_plot.transform(t)\n",
    "f,v = exp_surface_plot.gpr.predict(t_scaled)\n",
    "f = f.reshape(X1.shape)\n",
    "# PLOT DECISION SURFACE\n",
    "# ==================\n",
    "# Plot test instances and decision surface\n",
    "# ----------------------------------------------\n",
    "# Visualising the Test set results\n",
    "fig1 = plt.figure(figsize=(10,8),dpi=120)\n",
    "ax1 = fig1.add_subplot(111)\n",
    "X_set, y_set = X_test_surface_plot, y_test_surface_plot\n",
    "y_set[y_set==0] = -1\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d_set = 1-y_set*classifier.decision_function(X_set)\n",
    "else:\n",
    "    pred_x = classifier.predict(X_set)\n",
    "    pred_x[pred_x==0] = -1\n",
    "    d_set = y_set*pred_x\n",
    "xi_set = np.max([[np.zeros(d_set.size)],[d_set]],axis=0).ravel()\n",
    "if hasattr(classifier, \"decision_function\"):\n",
    "    d = classifier.decision_function(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape)\n",
    "    ax1.contour(X1, X2, d, levels=[0], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set>1,0]\n",
    "    y = X_set[xi_set>1,1]\n",
    "else:\n",
    "    d = classifier.predict_proba(np.array([X1.ravel(), X2.ravel()]).T)[:, 1].reshape(X1.shape)\n",
    "    ax1.contour(X1, X2, d, levels=[0.5], colors='black', linestyles='dashed')\n",
    "    ax1.contourf(X1, X2, Z, alpha = 0.3, cmap = matplotlib.colors.ListedColormap(('red', 'blue')))\n",
    "    x = X_set[xi_set==0,0]\n",
    "    y = X_set[xi_set==0,1]\n",
    "\n",
    "f_set = table_surface_plot['eta'].to_numpy()[::-1]\n",
    "f_set = np.unique(np.around(np.append(f_set, f.max()), decimals=2))\n",
    "cs = ax1.contourf(X1, X2, f, f_set, origin='upper', cmap='gray', alpha=0.5)\n",
    "ax1.contour(X1, X2, f, f_set, colors='black')\n",
    "cbar = fig1.colorbar(cs, pad=0.0, shrink=0.80)\n",
    "cbar.ax.set_title(r'$f$', fontsize=40, loc='left')\n",
    "cbar.set_label(r'$\\eta$', labelpad=-10, y=1.10, rotation=0, fontsize=30)\n",
    "dots = ['red','blue']\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    ax1.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                color = dots[i], label = '{}'.format('no purchase' if i==0 else 'purchase'), alpha=0.7, s=150,marker='x', linewidth=5)\n",
    "# Plot slack variables magnitudes\n",
    "ax1.scatter(x, y, s=150, facecolors='none', edgecolors='g', label='misclassified', linewidths=5)\n",
    "\n",
    "ax1.set_xlabel('Age',fontsize=40)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Test set',fontsize=40)\n",
    "ax1.legend(loc='lower left', framealpha=0.5, prop={'size': 30}, labelspacing=0.0)\n",
    "ax1.set_xlim(X1_min, X1_max)\n",
    "ax1.set_ylim(X2_min, X2_max)\n",
    "plt.tight_layout()\n",
    "path_fig_fx_test = \"drive/My Drive/NIPS2020/results/socialadsnet/fig_fx_test_{clf}_yhat{yhat}_pca{pca}.svg\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
    "plt.savefig(path_fig_fx_test, bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x737XLArx4ev"
   },
   "outputs": [],
   "source": [
    "report_table_concat = pd.concat(report_table)\n",
    "table_by_row_index = report_table_concat.groupby(report_table_concat.index)\n",
    "report_table_mean = table_by_row_index.mean()\n",
    "report_table_std = table_by_row_index.std()\n",
    "report_table_median = table_by_row_index.median()\n",
    "report_table_q1 = table_by_row_index.quantile(q=0.25)\n",
    "report_table_q3 = table_by_row_index.quantile(q=0.75)\n",
    "\n",
    "report_criteria_concat = pd.concat(report_criteria)\n",
    "table_by_row_index = report_criteria_concat.groupby(report_criteria_concat.index)\n",
    "report_criteria_mean = table_by_row_index.mean()\n",
    "report_criteria_std = table_by_row_index.std()\n",
    "report_criteria_median = table_by_row_index.median()\n",
    "report_criteria_q1 = table_by_row_index.quantile(q=0.25)\n",
    "report_criteria_q3 = table_by_row_index.quantile(q=0.75)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "socialadsnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
