{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_mlp",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaTPMXjDvlWJE7dx8U5xht",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cesar-claros/synergistic/blob/master/imdb_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4sBUso-gM_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install gpytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FymsszQy2n68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended #1\n",
        "! sudo apt-get install dvipng texlive-fonts-recommended #2\n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip #3\n",
        "! unzip type1cm.zip -d /tmp/type1cm #4\n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins  #5\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm #6\n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm #7\n",
        "! sudo texhash #8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gzdUCWgQOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "9219d486-ca27-467d-b372-b01f665bbd76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pODgafakgcZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"drive/My Drive/NIPS2020/auxfunc/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/datasets/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/style/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/runs/\" ."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrowTWaDjHhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKBZk4trqzQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "3dc42141-16e7-477b-caa2-0c3771baf98b"
      },
      "source": [
        "# Imports\n",
        "import io #Used as buffer\n",
        "import sys\n",
        "import matplotlib\n",
        "import tensorflow as tf # Keras model for MNIST \n",
        "# matplotlib.use('qt5Agg')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import auxfunc.sigfunc as sgn\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from scipy.stats import entropy, spearmanr\n",
        "from sklearn import model_selection, svm, ensemble, linear_model, pipeline, \\\n",
        "      tree, neighbors, discriminant_analysis, gaussian_process, preprocessing, impute, decomposition\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n",
        "plt.style.use(['ggplot','style/style.mplstyle'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPr-qGxurI6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Define LSTM architecture\n",
        "def LSTM_model(top_words,emb_vector_length,max_review_length):\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Embedding(top_words,emb_vector_length,input_length=max_review_length))\n",
        "    model.add(tf.keras.layers.LSTM(100))\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "            units=1, kernel_initializer='normal', activation='sigmoid'\n",
        "    ))\n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYYvRG4AmtEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Signaling function fitting and evaluation\n",
        "def signalingFunction(X_train, y_train, y_train_pred_th, X_val, y_val, y_val_pred_th, X_test, y_test, y_test_pred_th, kernel='exponential', norm='l01'):\n",
        "    # X_train, X_val should be scaled\n",
        "    # Fit signaling function \n",
        "    exp = sgn.signaling(norm=norm) # idx = [train,test,val]\n",
        "    exp.fit(X_train, y_train, y_train_pred_th, kernel=kernel, n_iter=500, lr=0.01)\n",
        "    table_val = exp.evaluate(X_val, y_val, y_val_pred_th, rule_grid=np.linspace(0,3,30, endpoint=False))\n",
        "    table_test = exp.test(X_test, y_test, y_test_pred_th, table_val['rule'].to_numpy(), table_val['eta'].to_numpy())\n",
        "    table = pd.concat([table_val,table_test],axis=1)\n",
        "    return table, exp"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRVYBv5lxPJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Initialize model\n",
        "def init_model(input_dim, objective):\n",
        "    model = MLP_model(input_dim=input_dim, objective=objective)\n",
        "    if objective=='svm':\n",
        "        loss = tf.keras.losses.hinge\n",
        "        metric = ['hinge']\n",
        "\n",
        "    elif objective=='softmax':\n",
        "        loss = tf.keras.losses.binary_crossentropy\n",
        "        metric = ['accuracy']\n",
        "\n",
        "    model.compile(loss=loss,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=metric)\n",
        "    # model.summary()\n",
        "    print('loss={}'.format(loss.__name__))\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMK50NRixYI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Soft and thresholded output predictions\n",
        "def pred_output(model, X, objective):\n",
        "    if objective=='svm':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] >= 0 else 0 for i in y_pred_soft])\n",
        "    elif objective=='softmax':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] > 0.5 else 0 for i in y_pred_soft])\n",
        "    return y_pred_soft, y_pred_th"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nf3lDBxjZcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Jaccard similarity index\n",
        "def jaccard_similarity(list1, list2):\n",
        "    s1 = set(list1)\n",
        "    s2 = set(list2)\n",
        "    return len(s1.intersection(s2)) / len(s1.union(s2))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyWbCZTIjbiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Baseline comparison\n",
        "def baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf):\n",
        "      if clf=='svm':\n",
        "          direction = 'closer'\n",
        "          crit_val = np.abs(y_val_pred_soft.ravel())\n",
        "          crit_test = np.abs(y_test_pred_soft.ravel())\n",
        "      else:\n",
        "          direction = 'further'\n",
        "          p_val = np.concatenate((y_val_pred_soft,1-y_val_pred_soft),axis=1)\n",
        "          crit_val = entropy(p_val, axis=1, base=2)\n",
        "          p_test = np.concatenate((y_test_pred_soft,1-y_test_pred_soft),axis=1)\n",
        "          crit_test = entropy(p_test, axis=1, base=2)\n",
        "      \n",
        "      critFunc = sgn.critEvaluation(norm='l01',direction=direction)\n",
        "      d_val = critFunc.evaluate(y_val, y_val_pred_th, crit_val)\n",
        "      d_test = critFunc.test(y_test, y_test_pred_th, crit_test, d_val['thresh'].to_numpy())\n",
        "      crit_table = pd.concat([d_val,d_test],axis=1)\n",
        "\n",
        "      gamma = table['rule'].to_numpy().reshape(-1,1)\n",
        "      f_test = exp.gpr_mean_test + gamma*np.sqrt(exp.gpr_var_test)\n",
        "      eta = table['eta'].to_numpy().reshape(-1,1)\n",
        "      theta = crit_table['thresh'].to_numpy().reshape(-1,1)\n",
        "      if direction == 'closer':\n",
        "        f_mask, f_idx = np.nonzero(f_test>eta)\n",
        "      else:\n",
        "        f_mask, f_idx = np.nonzero(f_test<eta)\n",
        "      crit_mask, crit_idx = np.nonzero(crit_test.reshape(1,-1)<theta)\n",
        "      print(list(np.unique(f_mask)))\n",
        "      print(list(np.unique(crit_mask)))\n",
        "      print(f_test.shape[0])\n",
        "      shared = set(list(np.unique(f_mask))).intersection(set(list(np.unique(crit_mask))))\n",
        "      J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan for i in range(f_test.shape[0])]\n",
        "      # if (list(np.unique(f_mask))==list(np.unique(crit_mask))):\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) for i in np.unique(f_mask)]\n",
        "      # else:\n",
        "      #   shared = set(a).intersection(set(b))\n",
        "      #   union = set(a).union(set(b))\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan  for i in union]\n",
        "      crit_table['jaccard']=J\n",
        "      Sp = [spearmanr(f_test[i,:],crit_test)[0] for i in range(f_test.shape[0])]\n",
        "      crit_table['spearman'] = Sp\n",
        "      crit_table['gamma'] = gamma\n",
        "      return crit_table"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3VCXn3_rTYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "0a29dc89-d14c-47d4-9471-c327f79697f8"
      },
      "source": [
        "# %%\n",
        "# INITIALIZATION\n",
        "# ==============\n",
        "# EXPERIMENT SETUP\n",
        "# ================\n",
        "top_words = 5000\n",
        "max_review_length = 500\n",
        "emb_vector_length = 32\n",
        "# Load data set\n",
        "(Data_X, Data_y), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=top_words)\n",
        "\n",
        "Data_X = tf.keras.preprocessing.sequence.pad_sequences(Data_X, maxlen=max_review_length)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "print(\"Number of original training examples:\", len(Data_X))\n",
        "# For reproducibility\n",
        "tf.random.set_seed(54321)\n",
        "np.random.seed(12345)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe3b9cc90d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jsIZNLPri8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "a9c46029-6d9d-4b0e-feac-ce13b2f8dacc"
      },
      "source": [
        "#%%\n",
        "# Assign labels\n",
        "report_table = []\n",
        "report_criteria = []\n",
        "report_plot = []\n",
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=123)\n",
        "clf = 'svm'\n",
        "addPredictions = False\n",
        "applyPCA = False\n",
        "for sample, test in kf.split(Data_X):\n",
        "    sample = sample[:12500]\n",
        "    test = test[:2000]\n",
        "    X = Data_X[sample]\n",
        "    y = Data_y[sample]\n",
        "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "    X_test = Data_X[test]\n",
        "    y_test = Data_y[test]\n",
        "\n",
        "    # TRAINING MODEL\n",
        "    model = init_model(input_dim=X.shape[1], objective=clf)\n",
        "    model.fit(X_train, y_train, batch_size=64, epochs=5, verbose=0, validation_data=(X_val, y_val))\n",
        "    X_test = scaleX.transform(imputeX.transform(X_test))\n",
        "\n",
        "    y_train_pred_soft, y_train_pred_th = pred_output(model, X_train, clf)\n",
        "    print('accuracy(Train)={}'.format(np.sum(y_train==y_train_pred_th)/np.size(y_train)))\n",
        "    y_val_pred_soft, y_val_pred_th = pred_output(model, X_val, clf)\n",
        "    y_test_pred_soft, y_test_pred_th = pred_output(model, X_test, clf)\n",
        "\n",
        "    layer_outputs = [layer.output for layer in model.layers] \n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "    X_train_GP = activation_model.predict(X_train)[1]\n",
        "    X_val_GP = activation_model.predict(X_val)[1]\n",
        "    X_test_GP = activation_model.predict(X_test)[1]\n",
        "\n",
        "    if addPredictions:\n",
        "            # Add predictions\n",
        "            X_train_GP = np.concatenate((X_train, y_train_pred_soft), axis=1)\n",
        "            X_val_GP = np.concatenate((X_val, y_val_pred_soft), axis=1)\n",
        "            X_test_GP = np.concatenate((X_test, y_test_pred_soft), axis=1)\n",
        "    scaleX_GP = preprocessing.StandardScaler().fit(np.concatenate((X_train_GP, X_val_GP), axis=0))\n",
        "    X_train_GP = scaleX_GP.transform(X_train_GP)\n",
        "    X_val_GP = scaleX_GP.transform(X_val_GP)\n",
        "    X_test_GP = scaleX_GP.transform(X_test_GP)\n",
        "    if applyPCA:\n",
        "            pca_GP = decomposition.PCA(.99).fit(np.concatenate((X_train_GP, X_val_GP), axis=0)) # set percentage of energy preserved by PCA\n",
        "            # Apply PCA transform to all sets\n",
        "            X_train_GP = pca_GP.transform(X_train_GP)\n",
        "            X_val_GP = pca_GP.transform(X_val_GP)\n",
        "            X_test_GP = pca_GP.transform(X_test_GP)\n",
        "\n",
        "    table, exp = signalingFunction(X_train_GP, y_train, y_train_pred_th, X_val_GP, y_val, y_val_pred_th, X_test_GP, y_test, y_test_pred_th)\n",
        "    report_table.append(table)\n",
        "    # Baseline for comparison\n",
        "    crit_table = baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf)\n",
        "    report_criteria.append(crit_table)\n",
        "    del(model)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dadf347d7b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# TRAINING MODEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaleX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputeX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-3a9992131cec>\u001b[0m in \u001b[0;36minit_model\u001b[0;34m(input_dim, objective)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Initialize model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'svm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhinge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLP_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlQtQPDGFE9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reverse lookup\n",
        "INDEX_FROM = 3\n",
        "word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj6x1QVqcRgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot signaled instances\n",
        "rho = 0.05\n",
        "rule = table.loc[table.rho_user == rho]['rule'].to_numpy()\n",
        "eta = table.loc[table.rho_user == rho]['eta'].to_numpy()\n",
        "f_test = exp.gpr_mean_test+rule*np.sqrt(exp.gpr_var_test)\n",
        "top_n = 8 # Top n selected instances in test set\n",
        "top_f_idx = np.argpartition(f_test, -top_n)[-top_n:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqv4gVyc1kF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "cda5f429-22ad-4802-955a-18b71eee3a0c"
      },
      "source": [
        "for i in top_f_idx:\n",
        "  print(' '.join(id_to_word[id] for id in X_test[i,:] )+\\\n",
        "        '\\n y={}'.format(y_test[i])+', y_pred={}'.format(y_test_pred_th[i])+\\\n",
        "        ', H={}'.format(crit_test[i])+'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> in <UNK> a film tales of manhattan told a set of stories that were basically <UNK> but tied together with a suit of <UNK> evening wear each story began when the <UNK> were passed from one owner charles <UNK> for instance to another <UNK> <UNK> <UNK> <UNK> a superior film and a great western has a similar plot twist initially it is about how jimmy stewart is seeking stephen <UNK> <UNK> for some deadly <UNK> but in the course of the film the two men get into a shooting contest the prize given by <UNK> <UNK> <UNK> will <UNK> being one of the new <UNK> <UNK> stewart barely beats out <UNK> but the gun is stolen from stewart and the chase is on br br the gun passes from hand to hand including john <UNK> as an arrogant <UNK> who <UNK> does not know when to stop being arrogant to rock hudson in a surprising role and a brief one at that to charles <UNK> to dan <UNK> as the <UNK> deadly and psychotic <UNK> johnny dean to <UNK> eventually it does return to stewart br br the film is <UNK> directed by anthony mann every character has a wide variety of experiences <UNK> gets the <UNK> literally over <UNK> dead body <UNK> forces the issue but he loses it to <UNK> who is faster on the draw not that <UNK> is stupid enough to fight for the <UNK> as he and shelley winter look at <UNK> in the distance winter who watched <UNK> kill her former boy friend <UNK> drops her <UNK> for the <UNK> <UNK> to ask why he put up with <UNK> <UNK> for the gun <UNK> <UNK> explains he can wait some opportunity will come up later on i e when he can <UNK> kill <UNK> and get back the <UNK> br br the characters are remarkably human winters first appears as the future bride of <UNK> but she sees a really big negative side to him an <UNK> side <UNK> is aware of this <UNK> and it helps lead to his destruction other characters have realistic touches such as j c <UNK> as an army <UNK> who fights an indian attack with <UNK> and <UNK> friend <UNK> mitchell oh yes and with <UNK> fellow soldier tony curtis <UNK> makes one believe this soldier has been on a hundred <UNK> before since <UNK> probably <UNK> had showed emotions in other films in it's a wonderful life he showed a degree of anger at times and also a near nervous <UNK> when he thinks everything is wrong with his life but here he showed a <UNK> anger at the <UNK> of a surprised <UNK> who normally would show such anger himself br br the parts of this film fit very <UNK> together under <UNK> competent hands this is one western that never wears out as the audience watches the travels of a <UNK> <UNK>\n",
            " y=1, y_pred=1, H=0.9643915295600891\n",
            "\n",
            "although all the technical problems of sound had been <UNK> very quickly it took longer to <UNK> the questions of how talking pictures should look how they should be <UNK> and how they should be acted the <UNK> is a key picture in that it shows the extent to which <UNK> moments can convey story <UNK> the power images without <UNK> the <UNK> of sound and dialogue br br this is not to say the <UNK> is truly a <UNK> to the golden days of the <UNK> for one thing many silent pictures were not so purely visual in their narrative and were <UNK> with title cards but what the <UNK> has is the self <UNK> to <UNK> moments between dialogues to focus on reactions more than <UNK> and to let shots play out simply for atmosphere br br director john ford for all his <UNK> was a filmmaker who appears to have put in effort in <UNK> to how interested he was in the material if he thought a story was silly he just did it half <UNK> luckily the <UNK> with its depiction of community <UNK> working class life and most importantly irish setting was everything ford loved and the result is one of his finest works in it ford only really <UNK> too kinds of shot the first is of places  the <UNK> streets <UNK> in <UNK> and darkness so their <UNK> <UNK> cannot be seen <UNK> <UNK> where the walls and <UNK> seem to press in on us the second is of faces striking close ups against plain backgrounds usually without dialogue focusing us upon the inner conflicts of these people br br lead man victor <UNK> fits perfectly within this character and this manner of filming him <UNK> performance does not look like much being as it is about 90 drunk act but the other 10 is <UNK> <UNK> as here and there his <UNK> <UNK> has what <UNK> <UNK> to as a moment of <UNK> with such performances are oscars won <UNK> is <UNK> by a spot on supporting cast among whom there are no weak <UNK> in particular it is nice to have donald <UNK> and <UNK> <UNK> usually only seen in comic relief roles playing straight dramatic parts for once although <UNK> appearance does contain one or two jokes the tone of the scene and much of his manner is serious not only do these two deliver incredibly deep performances their <UNK> to most viewers as comedy players gives an added note of <UNK> to their part in this tragedy br br <UNK> who produced the <UNK> were perhaps the most <UNK> and willing to take <UNK> of all the major studios thanks to this we are able to see a <UNK> story with a <UNK> anti hero at its <UNK> which could easily have been a <UNK> over <UNK> mess instead filled with a moody atmosphere and depth of character which keeps us watching and draws us into its world\n",
            " y=1, y_pred=0, H=0.9954509139060974\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> by far the most important <UNK> for any film following confidence <UNK> is that they must at least occasionally be able to pull one over on us as well as their dumb <UNK> marks the cops the mob and <UNK> each other but this film never pulls this off every <UNK> can be seen coming a mile off especially the <UNK> neither are they very interesting <UNK> or sophisticated perhaps <UNK> hoped to <UNK> for this with <UNK> dialogue and complex psychological relationships if so he failed the lines are alright but they're delivered in such a stilted <UNK> <UNK> way that i thought perhaps some clever point was being made about us all acting all the time but it wasn't as for the psychological complexity the main character's a bit <UNK> and makes some ridiculously forced <UNK> <UNK> about her father thinking she's a <UNK> but she gets over it i really liked the street scenes though looked just like an edward hopper painting\n",
            " y=0, y_pred=0, H=0.6437748074531555\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> warning minor spoilers br br i ran into this one <UNK> through and watched from there not knowing what it was or what the plot was it certainly held my attention i didn't know until the ending that it was based on a true story the guy she used to do the dirty <UNK> came out looking like a seriously nice guy who just got his head twisted around by a <UNK> girl i have to question how true to life that portrayal is anyone who would murder a husband and wife as they <UNK> just can't be entirely nice still i did have some sympathy for him as he had been set up and taken advantage of that much was made clear br br my main complaint is with the ending here comes the biggest spoiler skip this <UNK> if you don't want to learn it a few minutes before it ended there seemed no way for the truth to be discovered the way it got discovered was in a <UNK> operation but my question is how did the police get convinced to go along with it the movie didn't show us that and it seemed a bit too <UNK> absent the explanation of how they were <UNK> to do it br br i think the way they handled that was done for dramatic purposes as the <UNK> of the explanation <UNK> an <UNK> of suspense to the crucial scene which otherwise wouldn't have been there we would already have known what the scene was about and what was going on with brad in it br br otherwise this is a pretty good film i give it 7 10 it made me think now i'm interested to find out the facts of the real case br br one more thing the movie was done in 1996 some of the reviews here seem to be <UNK> it as a more recent movie br br p s <UNK> <UNK> is lovely i hadn't seen her before she can act a little too always a plus in her line of work lol\n",
            " y=1, y_pred=0, H=0.8664717078208923\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> it is not every film's job to <UNK> you <UNK> i will take an ambitious failure over a mass market hit any day while this really can't be described as a failure the sum of its parts remains <UNK> that <UNK> quality <UNK> me into watching it again and again this is a challenging <UNK> movie that does not wrap things up <UNK> the problem with the movie is in its structure its <UNK> plot seems to be <UNK> up just as a second ending is <UNK> on though everything is technically <UNK> the movie is exactly too long by that unit the long <UNK> climax of <UNK> <UNK> comes about 20 minutes late br br great cinematography often comes at the <UNK> of a decent script but here the innovative camera technique offers a wealth of visual ideas the <UNK> <UNK> is <UNK> and engaging a character is <UNK> <UNK> but his own hand in the <UNK> isn't the world depicted is <UNK> <UNK> and absurd keep your eyes <UNK> for a memorable technically <UNK> <UNK> that will make your jaw drop br br the <UNK> are stunning <UNK> chose to release the out of print <UNK> in the pan <UNK> format must have never seen it where is the dvd br br it is <UNK> how anyone could give this much originality a bad review you should see it at least once you get the sense that von <UNK> bit off more than he could <UNK> but this movie ends up being <UNK> for it i suspect he is familiar with <UNK> foreign <UNK> in which <UNK> <UNK> also <UNK> an american <UNK> and several welles movies that take <UNK> joy in technique as much as he does all von <UNK> movies explore the plight of the <UNK> <UNK> <UNK> <UNK> after <UNK> von <UNK> moved away from this type of <UNK> technical experiment towards dreary over rated un <UNK> <UNK> like breaking the waves and dancer in the dark\n",
            " y=1, y_pred=0, H=0.9486948847770691\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> here it is the first ever episode of friends where we get introduced to control freak <UNK> <UNK> <UNK> cox newly <UNK> <UNK> <UNK> david <UNK> <UNK> <UNK> <UNK> lisa <UNK> unknown actor and ladies man matt le <UNK> and very <UNK> <UNK> <UNK> matthew perry this is how the scene starts off until we introduced to the <UNK> and final friend <UNK> kid rachel green jennifer <UNK> br br the episode is better than most people give credit for like any new sitcom the first episode isn't always fantastic the acting in this episode isn't great because the cast cannot identify and <UNK> really believable in their new characters apart from <UNK> and perry who shine br br matt le <UNK> man his acting was down right dreadful because until later he gets more <UNK> but i think he tries to be funny but at most fails br br david <UNK> why does he over <UNK> every word he cannot speak normally but he became one of the funniest characters in later seasons but he isn't <UNK> and i cannot <UNK> with him jennifer <UNK> looks hot and does a good job as rachel green but we only see the real rachel later in the 1st season <UNK> cox looks quite <UNK> in this episode its <UNK> she looks totally different now more <UNK> she acting is a little <UNK> but <UNK> is in this 20 minute pilot lisa <UNK> and matthew perry i'm doing these two together because their comic timing and acting quality was superb and for lisa this was one of her first roles and she is so natural as <UNK> <UNK> and matthew perry is just matthew perry playing himself basically the episode quality does improve later such as the sets they looks dark and creepy in this episode and makes them seem <UNK> the acting is ok the characters gain confidence with each new scene and i am proud this is the pilot i hope we see the friends <UNK> cause they will always be there for us\n",
            " y=1, y_pred=0, H=0.9261688590049744\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> an old intellectual talks about what he <UNK> art in movies you get your hitchcock your chaplin your <UNK> and some other stuff prior to the <UNK> to <UNK> that he has no clue what is going on in <UNK> these days he throws in the matrix br br but it's not only the same lame film as art speech all over again this speech is reduced to <UNK> psychological <UNK> it ego super ego <UNK> <UNK> sexual <UNK> br br it is <UNK> with the cheesy effect of having <UNK> edited into the movies he is taking about for someone who is supposed to know much about movies his own is <UNK> speaking <UNK> br br to put it in <UNK> own words i saw 5 7 on the screen last night or in the words of a great movie maker br br mr <UNK> what you've just said is one of the most <UNK> idiotic things i have ever heard at no point in your <UNK> incoherent response were you even close to anything that could be considered a <UNK> thought everyone in this room is now <UNK> for having <UNK> to it i award you two points only and may god have <UNK> on your soul\n",
            " y=0, y_pred=1, H=0.9590057134628296\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> eight academy <UNK> it's beyond belief i can only think it was a very bad year even by hollywood standards with <UNK> as director and jack nicholson and <UNK> turner as leads i probably would have <UNK> the <UNK> and watched this anyway but the oscar <UNK> really sold it to me and i feel <UNK> cheated as a result br br so it's a black comedy is it can anyone tell me where the humour is in <UNK> honor it's certainly <UNK> the shooting in the head of a <UNK> wife is but another supposedly comic <UNK> in this intended farce about mafia life but with the exception of a joke about <UNK> favourite mexican <UNK> which i imagine is an old joke for americans who have been <UNK> forbidden from buying anything <UNK> for the last 50 years i failed to spot anything of a comic nature and i did try there is a lot of mafia cliché but cliché doesn't <UNK> humour in my book br br is it a romantic comedy of sorts never the characters and their relationships are so completely incredible and shallow that they are on a par with ben <UNK> and jennifer <UNK> in <UNK> br br is it a cleverly <UNK> parody about the mafia not in a million years the plot is just <UNK> absurd rather than <UNK> absurd and it usually just has the feel of a really bad and cheap mafia movie it feels more like a homage than a parody br br with one dimensional characters and little in the way of humour written for them the actors are left doing <UNK> accents and pulling faces well it isn't enough even when the face is being pulled by that master of the comic facial expression jack nicholson <UNK> with <UNK> up top <UNK> now is that meant to be a parody of <UNK> <UNK> <UNK> in the godfather oh who cares all i know is it isn't funny br br throw in some slow <UNK> direction this film drags on for 2 hours some <UNK> <UNK> and clichéd dialogue such as you remember the <UNK> well we're far bigger we'll track you down <UNK> you go and clichéd <UNK> and you'll be reaching for that fast forward button before you can say <UNK> <UNK> honor is far from being <UNK> masterpiece and is rather a very poor last work it's definitely one work in the great director's <UNK> that should be given a <UNK> <UNK> and <UNK> into the hudson river\n",
            " y=0, y_pred=0, H=0.9545286297798157\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhsLRvmXO-Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "46f981ed-285d-4f5e-de9b-d26b0f5b513e"
      },
      "source": [
        "top_H_idx = np.argpartition(crit_test, -top_n)[-top_n:]\n",
        "for i in top_H_idx:\n",
        "  print(' '.join(id_to_word[id] for id in X_test[i,:] )+\\\n",
        "        '\\n y={}'.format(y_test[i])+', y_pred={}'.format(y_test_pred_th[i])+\\\n",
        "        ', H={}'.format(crit_test[i])+'\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i really thought this wasn't that bad not a great work of art but <UNK> m was the stronger performer by far <UNK> <UNK> was overacting much of the time he was actually playing <UNK> which was very impressive and his lines were never forced besides he is an incredibly beautiful man really sexy add that to the talent and most anything he's been in is a lot more <UNK> he always gives his all even if some of the projects he's been involved in didn't quite hit the highest mark not the fault of the actor in most cases he's unfortunately been in some strange films that just didn't <UNK> at the box office always with a list actors but just not always a hit but he is worth every <UNK> of any dvd rented or purchased see the wedding date with <UNK> <UNK> one of his best overall films worth every <UNK> if you haven't seen it yet do then you'll understand that quote\n",
            " y=1, y_pred=1, H=0.9994180202484131\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> there's a lot going on in the college girl murders a mad scientist creates an almost <UNK> <UNK> gas before he can <UNK> the <UNK> of his discovery the scientist is killed by a <UNK> <UNK> <UNK> monk after a co ed is killed in a church by the gas <UNK> <UNK> is called in to investigate but the killing continues who can stop this mad killer who seems to be able to come and go as he <UNK> in and out of the college br br what works br br the killer what's not to like about a killer who <UNK> around wearing a vivid red <UNK> looking outfit complete with red <UNK> the white <UNK> he carries and uses very effectively stands out nicely against the bright red <UNK> although the idea of a killer in a <UNK> red <UNK> head outfit <UNK> around a girl's school is fairly far fetched it's one of the more sinister looking costumes i've seen br br <UNK> 60s music i really would like to track down the title music to the college girl murders it's got a <UNK> hip 60s feel to it that i just loved br br bizarre touches beyond the <UNK> red <UNK> and hood the movie features a <UNK> <UNK> a pit of <UNK> with a cage <UNK> <UNK> <UNK> <UNK> <UNK> a <UNK> placed <UNK> mini <UNK> go go <UNK> and mile high hair i would describe it as a cross between the 60s batman tv show and an italian giallo the college girl murders is a real treat for the eye br br the end let's just say that there are more twists than a mountain road just when you think the killer has been <UNK> here comes a <UNK> and <UNK> and <UNK> another br br what doesn't work br br chief inspector sir john i know the guy was meant to be comic relief but his <UNK> character has way too much screen time br br why have <UNK> previously i mentioned the <UNK> in the pit and while they are a nice touch they serve very little purpose why go through all the trouble and not use them br br <UNK> plot some of the college girl murders has no flow or <UNK> to it there are far too many moments throughout the movie when things come <UNK> to a <UNK> <UNK> better pacing would have made this a much more enjoyable movie br br i haven't seen many of these german <UNK> but of the few i have seen phantom of <UNK> <UNK> of <UNK> castle dead eyes of london this may be my favorite this one has a real <UNK> feel to it that i really go into had the plot <UNK> a little better i could have easily given the college girl murders a 7 10\n",
            " y=1, y_pred=0, H=0.9998515844345093\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> i've seen enough of both little richard in interviews and in performances and enough of poor <UNK> <UNK> into these 50s 60s musical <UNK> <UNK> to know that <UNK> was not the right actor for this role <UNK> was so right as david <UNK> in the <UNK> but fails utterly to capture the essence of little richard in this film br br actor <UNK> <UNK> who played little richard in why do <UNK> fall in love was a much more suitable choice having pulled off the <UNK> powerful but <UNK> persona br br if the performances are unconvincing then the film will be as well and this is what has happened here <UNK> over or missed entirely are <UNK> <UNK> into <UNK> and <UNK> what the <UNK> did so well in capturing the rise of the group <UNK> and all this film misses by a wide mark br br what is going on with director robert <UNK> who started off so well with the hollywood <UNK> he's a talented funny guy but hasn't delivered anything near that first effort\n",
            " y=0, y_pred=0, H=0.9999356865882874\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> the visuals and effects are up to par with the the original film and provide a lot of entertainment even if the storyline is essentially the same as the first two films it also seems a lot more <UNK> <UNK> than i remember the other films being if you're a big fan of flying <UNK> hair and <UNK> that can reach all the way down into your stomach you'll like this film\n",
            " y=1, y_pred=1, H=0.9998576045036316\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> im a huge m <UNK> fan that's why i ended up watching this movie honestly i doubt that if he wasn't in the movie i would of enjoyed it as much or even watched it but once i did watch it realize the story was pretty decent a bad ending i must say but i did see it coming it's a low budget movie and some of the actors weren't really good but all in all i rated this movie 7 10 br br the suspense of wondering what <UNK> was actually up to was what really <UNK> me interested in this movie br br its a good rental br br 7 10\n",
            " y=1, y_pred=1, H=0.999941885471344\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> sometimes it takes a film making master like <UNK> to bring that extra little something that unique <UNK> and <UNK> <UNK> that <UNK> a great movie or a great script into a masterpiece one for the ages br br it's not just that stephen king's story has enough meat and <UNK> making it difficult for even the most <UNK> of directors to miss heck even king himself didn't fare so bad it's how <UNK> <UNK> king's universe how he <UNK> the page into screen time that <UNK> the shining both a visual <UNK> and a <UNK> <UNK> in directing br br <UNK> miss <UNK> scene is as usually terrific the movie progresses with a <UNK> sharp lively pace even though it's neither fast nor heavily edited and it <UNK> at no less than <UNK> minutes the camera <UNK> through the <UNK> <UNK> of the overlook hotel like it is some kind of <UNK> <UNK> <UNK> for exploration <UNK> <UNK> shots <UNK> the <UNK> <UNK> <UNK> in all their <UNK> there's a <UNK> and <UNK> approach in how <UNK> <UNK> space that reminds me very much of how japanese directors worked in the sixties as if what is depicted is <UNK> to how all the different elements are <UNK> inside the frame br br certain images definitely stand out the first shot of <UNK> <UNK> accompanied off screen from the <UNK> of a ball like <UNK> of doom coming from some other floor or produced by the <UNK> itself as though it is an <UNK> of doom all by itself later on <UNK> to be nothing short of just that a red river <UNK> through the <UNK> <UNK> in slow motion jack hitting the door with the <UNK> the camera moving along with him <UNK> the action as it happens instead of remaining <UNK> as though it's the camera <UNK> through the door and not the <UNK> the ultra fast <UNK> in the <UNK> face <UNK> us inside his head before we see the two dead girls from his <UNK> and of course the bathroom scene br br much has been said of jack <UNK> <UNK> overacting his mad is not entirely successful because well he's jack nicholson the guy looks half mad anyway playing mad turns him into an exaggerated <UNK> of himself shelley <UNK> on the other hand is one of the most inspired casting choices <UNK> ever had coming from a <UNK> of fantastic performances for robert <UNK> in the seventies 3 women <UNK> like us <UNK> she brings to her character the right amounts of <UNK> and emotional <UNK> a terrific and very underrated actress\n",
            " y=1, y_pred=1, H=0.9999924302101135\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> <UNK> the movie was fairly good a good action plot with a fair amount of explosions and fight scenes but chuck <UNK> did hardly anything except for <UNK> the bomb and shoot a few characters the movie was very similar to the events of <UNK> 11 with a bin <UNK> like terrorist <UNK> a video to the president <UNK> and threatening to <UNK> it <UNK> <UNK> had some superb action roles taking out <UNK> <UNK> and various kick butt roles but there was a lack of chuck <UNK> <UNK> took over most of the action leaving <UNK> chuck with <UNK> on her computer but overall it was realistic and didn't lack the action but only did it on mr <UNK> part i gave the film 7 10\n",
            " y=1, y_pred=1, H=0.9999980926513672\n",
            "\n",
            "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> three story lines and not enough <UNK> them together inside man was very <UNK> and an <UNK> attempt to be artistic and realistic though having its moments the movie started off looking like a fast thriller which quickly <UNK> to a slow <UNK> jumped quickly between <UNK> and <UNK> and only barely picked up <UNK> again near the last 20 minutes i will give credit to denzel washington he played his part extremely well with a full grasp of his human side and not just the typical super detective with all the answers <UNK> <UNK> also did quite well with his <UNK> part as evil genius and criminal <UNK> both not the same in <UNK> overall though each person <UNK> created a great sub section yet when the parts finally came together and everything <UNK> there was no sudden ah ha or <UNK> of everything it all ended up with very little of the energy it began with with a lot of plot holes tons of questions and as i said earlier no where near spike lee's normal level i have to completely disagree with the so called professional critics this is not the movie they play it up to be\n",
            " y=0, y_pred=0, H=0.999999463558197\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX7WuJijg-Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_table_concat = pd.concat(report_table)\n",
        "table_by_row_index = report_table_concat.groupby(report_table_concat.index)\n",
        "report_table_mean = table_by_row_index.mean()\n",
        "report_table_std = table_by_row_index.std()\n",
        "\n",
        "report_criteria_concat = pd.concat(report_criteria)\n",
        "table_by_row_index = report_criteria_concat.groupby(report_criteria_concat.index)\n",
        "report_criteria_mean = table_by_row_index.mean()\n",
        "report_criteria_std = table_by_row_index.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zDE3LuFiAvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8561aab0-af6f-4211-d048-a2abb77bf548"
      },
      "source": [
        "report_table_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.14192</td>\n",
              "      <td>3.786</td>\n",
              "      <td>0.820517</td>\n",
              "      <td>1.596467e-04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.1471</td>\n",
              "      <td>3.218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02472</td>\n",
              "      <td>0.12280</td>\n",
              "      <td>16.776</td>\n",
              "      <td>0.672585</td>\n",
              "      <td>1.438608e-20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.1273</td>\n",
              "      <td>16.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.84</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.10184</td>\n",
              "      <td>31.026</td>\n",
              "      <td>0.448278</td>\n",
              "      <td>2.111505e-39</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0457</td>\n",
              "      <td>0.1063</td>\n",
              "      <td>30.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.26</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06064</td>\n",
              "      <td>0.08688</td>\n",
              "      <td>41.244</td>\n",
              "      <td>0.423398</td>\n",
              "      <td>1.133743e-41</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.0634</td>\n",
              "      <td>0.0886</td>\n",
              "      <td>41.738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>50.104</td>\n",
              "      <td>0.136592</td>\n",
              "      <td>5.266706e-43</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0745</td>\n",
              "      <td>50.980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rule  rho_user  error_val  ...  error_test  L_test  %reduction_test\n",
              "0  1.06      0.01    0.00560  ...      0.0049  0.1471            3.218\n",
              "1  1.20      0.05    0.02472  ...      0.0247  0.1273           16.284\n",
              "2  0.84      0.10    0.04568  ...      0.0457  0.1063           30.058\n",
              "3  1.26      0.15    0.06064  ...      0.0634  0.0886           41.738\n",
              "4  0.12      0.20    0.07376  ...      0.0775  0.0745           50.980\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zgyJyu4iCBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cb39105f-bc61-49e2-e1ff-25a644cd23fe"
      },
      "source": [
        "report_criteria_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00488</td>\n",
              "      <td>0.14264</td>\n",
              "      <td>3.306</td>\n",
              "      <td>0.998604</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>3.672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02320</td>\n",
              "      <td>0.12432</td>\n",
              "      <td>15.728</td>\n",
              "      <td>0.964553</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0242</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>15.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04408</td>\n",
              "      <td>0.10344</td>\n",
              "      <td>29.916</td>\n",
              "      <td>0.885287</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0452</td>\n",
              "      <td>0.1068</td>\n",
              "      <td>29.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06088</td>\n",
              "      <td>0.08664</td>\n",
              "      <td>41.324</td>\n",
              "      <td>0.774637</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>0.0866</td>\n",
              "      <td>43.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07608</td>\n",
              "      <td>0.07144</td>\n",
              "      <td>51.648</td>\n",
              "      <td>0.668580</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>54.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val    L_val  ...  error_test  L_test  %reduction_test\n",
              "0      0.01    0.00488  0.14264  ...      0.0057  0.1463            3.672\n",
              "1      0.05    0.02320  0.12432  ...      0.0242  0.1278           15.878\n",
              "2      0.10    0.04408  0.10344  ...      0.0452  0.1068           29.700\n",
              "3      0.15    0.06088  0.08664  ...      0.0654  0.0866           43.020\n",
              "4      0.20    0.07608  0.07144  ...      0.0825  0.0695           54.300\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neU88XQkAzny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b792c43-3fdb-48ee-d89a-e251ef90f666"
      },
      "source": [
        "report_table_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.176010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>0.007034</td>\n",
              "      <td>0.797076</td>\n",
              "      <td>0.219716</td>\n",
              "      <td>3.569270e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.009283</td>\n",
              "      <td>1.190869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.104536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.007595</td>\n",
              "      <td>2.114800</td>\n",
              "      <td>0.264298</td>\n",
              "      <td>3.187349e-20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.009425</td>\n",
              "      <td>1.828026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.221884</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002918</td>\n",
              "      <td>0.007857</td>\n",
              "      <td>2.533146</td>\n",
              "      <td>0.322871</td>\n",
              "      <td>4.721467e-39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.006535</td>\n",
              "      <td>0.008526</td>\n",
              "      <td>3.697022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.047855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.010188</td>\n",
              "      <td>4.406856</td>\n",
              "      <td>0.203426</td>\n",
              "      <td>2.432024e-41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>0.008569</td>\n",
              "      <td>3.804684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.009045</td>\n",
              "      <td>4.302619</td>\n",
              "      <td>0.043197</td>\n",
              "      <td>1.177661e-42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.010186</td>\n",
              "      <td>0.009670</td>\n",
              "      <td>5.632673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rule  rho_user  error_val  ...  error_test    L_test  %reduction_test\n",
              "0  1.176010       0.0   0.001265  ...    0.001817  0.009283         1.190869\n",
              "1  1.104536       0.0   0.003025  ...    0.002564  0.009425         1.828026\n",
              "2  1.221884       0.0   0.002918  ...    0.006535  0.008526         3.697022\n",
              "3  1.047855       0.0   0.004495  ...    0.006628  0.008569         3.804684\n",
              "4  0.178885       0.0   0.005127  ...    0.010186  0.009670         5.632673\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjaMD-kKNMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "95ed1e63-79df-4e52-e414-e7a7d519ef96"
      },
      "source": [
        "report_criteria_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.007357</td>\n",
              "      <td>0.659454</td>\n",
              "      <td>0.000779</td>\n",
              "      <td>0.004472</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>0.007032</td>\n",
              "      <td>1.738094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>1.788413</td>\n",
              "      <td>0.016886</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.003347</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>1.419972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002834</td>\n",
              "      <td>0.007164</td>\n",
              "      <td>2.081797</td>\n",
              "      <td>0.053454</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005251</td>\n",
              "      <td>0.006496</td>\n",
              "      <td>2.410187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.007785</td>\n",
              "      <td>3.379797</td>\n",
              "      <td>0.081735</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005067</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>1.744506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005370</td>\n",
              "      <td>0.008341</td>\n",
              "      <td>4.106479</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006225</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>2.760860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val     L_val  ...  error_test    L_test  %reduction_test\n",
              "0       0.0   0.000996  0.007357  ...    0.003054  0.007032         1.738094\n",
              "1       0.0   0.002871  0.006832  ...    0.003347  0.007023         1.419972\n",
              "2       0.0   0.002834  0.007164  ...    0.005251  0.006496         2.410187\n",
              "3       0.0   0.004625  0.007785  ...    0.005067  0.005878         1.744506\n",
              "4       0.0   0.005370  0.008341  ...    0.006225  0.006567         2.760860\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NU73I2FKP6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}