{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "imdb_lstm",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cesar-claros/synergistic/blob/master/imdb_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4sBUso-gM_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install gpytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FymsszQy2n68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! sudo apt-get install texlive-latex-recommended #1\n",
        "! sudo apt-get install dvipng texlive-fonts-recommended #2\n",
        "! wget http://mirrors.ctan.org/macros/latex/contrib/type1cm.zip #3\n",
        "! unzip type1cm.zip -d /tmp/type1cm #4\n",
        "! cd /tmp/type1cm/type1cm/ && sudo latex type1cm.ins  #5\n",
        "! sudo mkdir /usr/share/texmf/tex/latex/type1cm #6\n",
        "! sudo cp /tmp/type1cm/type1cm/type1cm.sty /usr/share/texmf/tex/latex/type1cm #7\n",
        "! sudo texhash #8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0gzdUCWgQOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "1469dbec-b146-4cde-b0cb-f3c446c7f767"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pODgafakgcZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r \"drive/My Drive/NIPS2020/auxfunc/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/datasets/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/style/\" .\n",
        "!cp -r \"drive/My Drive/NIPS2020/runs/\" ."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrowTWaDjHhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKBZk4trqzQV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d35024f1-9934-4188-8398-028246a87e58"
      },
      "source": [
        "# Imports\n",
        "import io #Used as buffer\n",
        "import sys\n",
        "import matplotlib\n",
        "import tensorflow as tf # Keras model for MNIST \n",
        "# matplotlib.use('qt5Agg')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import auxfunc.sigfunc as sgn\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from scipy.stats import entropy, spearmanr\n",
        "from sklearn import model_selection, svm, ensemble, linear_model, pipeline, \\\n",
        "      tree, neighbors, discriminant_analysis, gaussian_process, preprocessing, impute, decomposition\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, Matern\n",
        "plt.style.use(['ggplot','style/style.mplstyle'])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPr-qGxurI6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Define LSTM architecture\n",
        "def LSTM_model(top_words, emb_vector_length, max_review_length, objective, reg=0.01):\n",
        "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Embedding(top_words,emb_vector_length,input_length=max_review_length))\n",
        "    model.add(tf.keras.layers.LSTM(100))\n",
        "    if objective == 'svm':\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=1, kernel_initializer='uniform', activation='linear', kernel_regularizer=tf.keras.regularizers.l2(reg)\n",
        "        ))\n",
        "    elif objective == 'softmax':\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=1, kernel_initializer='uniform', activation='sigmoid'\n",
        "        ))\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYYvRG4AmtEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Signaling function fitting and evaluation\n",
        "def signalingFunction(X_train, y_train, y_train_pred_th, X_val, y_val, y_val_pred_th, X_test, y_test, y_test_pred_th, kernel='exponential', norm='l01'):\n",
        "    # X_train, X_val should be scaled\n",
        "    # Fit signaling function \n",
        "    exp = sgn.signaling(norm=norm) # idx = [train,test,val]\n",
        "    exp.fit(X_train, y_train, y_train_pred_th, kernel=kernel, n_iter=500, lr=0.01)\n",
        "    table_val = exp.evaluate(X_val, y_val, y_val_pred_th, rule_grid=np.linspace(0,3,30, endpoint=False))\n",
        "    table_test = exp.test(X_test, y_test, y_test_pred_th, table_val['rule'].to_numpy(), table_val['eta'].to_numpy())\n",
        "    table = pd.concat([table_val,table_test],axis=1)\n",
        "    return table, exp"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRVYBv5lxPJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Initialize model\n",
        "def init_model(input_dim, objective):\n",
        "    model = LSTM_model(top_words, emb_vector_length, max_review_length, objective)\n",
        "    if objective=='svm':\n",
        "        loss = tf.keras.losses.hinge\n",
        "        metric = ['hinge']\n",
        "\n",
        "    elif objective=='softmax':\n",
        "        loss = tf.keras.losses.binary_crossentropy\n",
        "        metric = ['accuracy']\n",
        "\n",
        "    model.compile(loss=loss,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=metric)\n",
        "    # model.summary()\n",
        "    print('loss={}'.format(loss.__name__))\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMK50NRixYI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Soft and thresholded output predictions\n",
        "def pred_output(model, X, objective):\n",
        "    if objective=='svm':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] >= 0 else 0 for i in y_pred_soft])\n",
        "    elif objective=='softmax':\n",
        "        y_pred_soft = model.predict(X)\n",
        "        y_pred_th = np.array([1 if i[0] > 0.5 else 0 for i in y_pred_soft])\n",
        "    return y_pred_soft, y_pred_th"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nf3lDBxjZcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Jaccard similarity index\n",
        "def jaccard_similarity(list1, list2):\n",
        "    s1 = set(list1)\n",
        "    s2 = set(list2)\n",
        "    return len(s1.intersection(s2)) / len(s1.union(s2))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyWbCZTIjbiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Baseline comparison\n",
        "def baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf):\n",
        "      if clf=='svm':\n",
        "          direction = 'closer'\n",
        "          crit_val = np.abs(y_val_pred_soft.ravel())\n",
        "          crit_test = np.abs(y_test_pred_soft.ravel())\n",
        "      else:\n",
        "          direction = 'further'\n",
        "          p_val = np.concatenate((y_val_pred_soft,1-y_val_pred_soft),axis=1)\n",
        "          crit_val = entropy(p_val, axis=1, base=2)\n",
        "          p_test = np.concatenate((y_test_pred_soft,1-y_test_pred_soft),axis=1)\n",
        "          crit_test = entropy(p_test, axis=1, base=2)\n",
        "      \n",
        "      critFunc = sgn.critEvaluation(norm='l01',direction=direction)\n",
        "      d_val = critFunc.evaluate(y_val, y_val_pred_th, crit_val)\n",
        "      d_test = critFunc.test(y_test, y_test_pred_th, crit_test, d_val['thresh'].to_numpy())\n",
        "      crit_table = pd.concat([d_val,d_test],axis=1)\n",
        "\n",
        "      gamma = table['rule'].to_numpy().reshape(-1,1)\n",
        "      f_test = exp.gpr_mean_test + gamma*np.sqrt(exp.gpr_var_test)\n",
        "      eta = table['eta'].to_numpy().reshape(-1,1)\n",
        "      theta = crit_table['thresh'].to_numpy().reshape(-1,1)\n",
        "      if direction == 'closer':\n",
        "        f_mask, f_idx = np.nonzero(f_test>eta)\n",
        "      else:\n",
        "        f_mask, f_idx = np.nonzero(f_test<eta)\n",
        "      crit_mask, crit_idx = np.nonzero(crit_test.reshape(1,-1)<theta)\n",
        "      print(list(np.unique(f_mask)))\n",
        "      print(list(np.unique(crit_mask)))\n",
        "      print(f_test.shape[0])\n",
        "      shared = set(list(np.unique(f_mask))).intersection(set(list(np.unique(crit_mask))))\n",
        "      J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan for i in range(f_test.shape[0])]\n",
        "      # if (list(np.unique(f_mask))==list(np.unique(crit_mask))):\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) for i in np.unique(f_mask)]\n",
        "      # else:\n",
        "      #   shared = set(a).intersection(set(b))\n",
        "      #   union = set(a).union(set(b))\n",
        "      #   J = [jaccard_similarity(crit_idx[crit_mask==i],f_idx[f_mask==i]) if i in shared else np.nan  for i in union]\n",
        "      crit_table['jaccard']=J\n",
        "      Sp = [spearmanr(f_test[i,:],crit_test)[0] for i in range(f_test.shape[0])]\n",
        "      crit_table['spearman'] = Sp\n",
        "      crit_table['gamma'] = gamma\n",
        "      return crit_table"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3VCXn3_rTYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "93ab8f2d-8bce-4554-bac6-5ae8db9ff3cb"
      },
      "source": [
        "# %%\n",
        "# INITIALIZATION\n",
        "# ==============\n",
        "# EXPERIMENT SETUP\n",
        "# ================\n",
        "top_words = 5000\n",
        "max_review_length = 500\n",
        "emb_vector_length = 32\n",
        "# Load data set\n",
        "(Data_X, Data_y), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=top_words)\n",
        "Data_X = tf.keras.preprocessing.sequence.pad_sequences(Data_X, maxlen=max_review_length)\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
        "print(\"Number of original training examples:\", len(Data_X))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "Number of original training examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jsIZNLPri8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f29fac4-26ed-4fea-f287-29d49e5b5c8a"
      },
      "source": [
        "# For reproducibility\n",
        "tf.random.set_seed(54321)\n",
        "np.random.seed(12345)\n",
        "torch.manual_seed(0)\n",
        "#%%\n",
        "# Assign labels\n",
        "report_table = []\n",
        "report_criteria = []\n",
        "report_plot = []\n",
        "kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=123)\n",
        "clf = 'softmax'\n",
        "addPredictions = True\n",
        "applyPCA = False\n",
        "accuracy = 0\n",
        "for sample, test in kf.split(Data_X):\n",
        "    sample = sample[:12500]\n",
        "    test = test[:2000]\n",
        "    X = Data_X[sample]\n",
        "    y = Data_y[sample]\n",
        "    X_train, X_val, y_train, y_val = model_selection.train_test_split(X, y, test_size=0.20, random_state=123)\n",
        "    X_test = Data_X[test]\n",
        "    y_test = Data_y[test]\n",
        "\n",
        "    # TRAINING MODEL\n",
        "    model = init_model(input_dim=X.shape[1], objective=clf)\n",
        "    model.fit(X_train, y_train, batch_size=64, epochs=5, verbose=0, validation_data=(X_val, y_val))\n",
        "    # X_test = scaleX.transform(imputeX.transform(X_test))\n",
        "\n",
        "    y_train_pred_soft, y_train_pred_th = pred_output(model, X_train, clf)\n",
        "    print('accuracy(Train)={}'.format(np.sum(y_train==y_train_pred_th)/np.size(y_train)))\n",
        "    y_val_pred_soft, y_val_pred_th = pred_output(model, X_val, clf)\n",
        "    # print('accuracy(Val)={}'.format(np.sum(y_val==y_val_pred_th)/np.size(y_val)))\n",
        "    y_test_pred_soft, y_test_pred_th = pred_output(model, X_test, clf)\n",
        "\n",
        "    layer_outputs = [layer.output for layer in model.layers] \n",
        "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "    X_train_GP = activation_model.predict(X_train)[1]\n",
        "    X_val_GP = activation_model.predict(X_val)[1]\n",
        "    X_test_GP = activation_model.predict(X_test)[1]\n",
        "\n",
        "    if addPredictions:\n",
        "            # Add predictions\n",
        "            X_train_GP = np.concatenate((X_train_GP, y_train_pred_soft), axis=1)\n",
        "            X_val_GP = np.concatenate((X_val_GP, y_val_pred_soft), axis=1)\n",
        "            X_test_GP = np.concatenate((X_test_GP, y_test_pred_soft), axis=1)\n",
        "    scaleX_GP = preprocessing.StandardScaler().fit(np.concatenate((X_train_GP, X_val_GP), axis=0))\n",
        "    X_train_GP = scaleX_GP.transform(X_train_GP)\n",
        "    X_val_GP = scaleX_GP.transform(X_val_GP)\n",
        "    X_test_GP = scaleX_GP.transform(X_test_GP)\n",
        "    if applyPCA:\n",
        "            pca_GP = decomposition.PCA(.99).fit(np.concatenate((X_train_GP, X_val_GP), axis=0)) # set percentage of energy preserved by PCA\n",
        "            # Apply PCA transform to all sets\n",
        "            X_train_GP = pca_GP.transform(X_train_GP)\n",
        "            X_val_GP = pca_GP.transform(X_val_GP)\n",
        "            X_test_GP = pca_GP.transform(X_test_GP)\n",
        "\n",
        "    table, exp = signalingFunction(X_train_GP, y_train, y_train_pred_th, X_val_GP, y_val, y_val_pred_th, X_test_GP, y_test, y_test_pred_th)\n",
        "    report_table.append(table)\n",
        "    # Baseline for comparison\n",
        "    crit_table = baselineCriteria(y_val, y_val_pred_soft, y_val_pred_th, y_test, y_test_pred_soft, y_test_pred_th, table, exp, clf)\n",
        "    report_criteria.append(crit_table)\n",
        "\n",
        "    score = np.sum(y_val==y_val_pred_th)/np.size(y_val)\n",
        "    if accuracy < score:\n",
        "      accuracy = score\n",
        "      table_best = table\n",
        "      crit_table_best = crit_table\n",
        "      exp_best = exp\n",
        "      y_test_best = y_test\n",
        "      y_test_pred_soft_best = y_test_pred_soft\n",
        "      y_test_pred_th_best = y_test_pred_th\n",
        "      X_test_best = X_test\n",
        "    del(model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9502\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: -0.310  noise: 0.019\n",
            "Iter 492/500 - Loss: -0.311  noise: 0.019\n",
            "Iter 493/500 - Loss: -0.315  noise: 0.019\n",
            "Iter 494/500 - Loss: -0.311  noise: 0.019\n",
            "Iter 495/500 - Loss: -0.312  noise: 0.019\n",
            "Iter 496/500 - Loss: -0.312  noise: 0.018\n",
            "Iter 497/500 - Loss: -0.316  noise: 0.018\n",
            "Iter 498/500 - Loss: -0.313  noise: 0.018\n",
            "Iter 499/500 - Loss: -0.311  noise: 0.018\n",
            "Iter 500/500 - Loss: -0.315  noise: 0.018\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.8687\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: 0.177  noise: 0.054\n",
            "Iter 492/500 - Loss: 0.178  noise: 0.054\n",
            "Iter 493/500 - Loss: 0.177  noise: 0.054\n",
            "Iter 494/500 - Loss: 0.176  noise: 0.054\n",
            "Iter 495/500 - Loss: 0.176  noise: 0.054\n",
            "Iter 496/500 - Loss: 0.179  noise: 0.054\n",
            "Iter 497/500 - Loss: 0.177  noise: 0.054\n",
            "Iter 498/500 - Loss: 0.178  noise: 0.054\n",
            "Iter 499/500 - Loss: 0.179  noise: 0.054\n",
            "Iter 500/500 - Loss: 0.177  noise: 0.054\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.8941\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: -0.075  noise: 0.030\n",
            "Iter 492/500 - Loss: -0.079  noise: 0.030\n",
            "Iter 493/500 - Loss: -0.079  noise: 0.030\n",
            "Iter 494/500 - Loss: -0.077  noise: 0.030\n",
            "Iter 495/500 - Loss: -0.078  noise: 0.030\n",
            "Iter 496/500 - Loss: -0.077  noise: 0.030\n",
            "Iter 497/500 - Loss: -0.079  noise: 0.030\n",
            "Iter 498/500 - Loss: -0.078  noise: 0.030\n",
            "Iter 499/500 - Loss: -0.078  noise: 0.030\n",
            "Iter 500/500 - Loss: -0.075  noise: 0.030\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9536\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: -0.309  noise: 0.019\n",
            "Iter 492/500 - Loss: -0.309  noise: 0.019\n",
            "Iter 493/500 - Loss: -0.309  noise: 0.019\n",
            "Iter 494/500 - Loss: -0.309  noise: 0.019\n",
            "Iter 495/500 - Loss: -0.309  noise: 0.019\n",
            "Iter 496/500 - Loss: -0.307  noise: 0.019\n",
            "Iter 497/500 - Loss: -0.310  noise: 0.019\n",
            "Iter 498/500 - Loss: -0.311  noise: 0.019\n",
            "Iter 499/500 - Loss: -0.307  noise: 0.019\n",
            "Iter 500/500 - Loss: -0.309  noise: 0.019\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n",
            "loss=binary_crossentropy\n",
            "accuracy(Train)=0.9296\n",
            "initializing cuda...\n",
            "lr=0.01, n_iterations=500\n",
            "Iter 491/500 - Loss: -0.270  noise: 0.019\n",
            "Iter 492/500 - Loss: -0.271  noise: 0.019\n",
            "Iter 493/500 - Loss: -0.272  noise: 0.019\n",
            "Iter 494/500 - Loss: -0.273  noise: 0.019\n",
            "Iter 495/500 - Loss: -0.271  noise: 0.019\n",
            "Iter 496/500 - Loss: -0.273  noise: 0.019\n",
            "Iter 497/500 - Loss: -0.274  noise: 0.019\n",
            "Iter 498/500 - Loss: -0.272  noise: 0.019\n",
            "Iter 499/500 - Loss: -0.273  noise: 0.019\n",
            "Iter 500/500 - Loss: -0.273  noise: 0.019\n",
            "evaluating with cuda...\n",
            "evaluating with cuda...\n",
            "[0, 1, 2, 3, 4]\n",
            "[0, 1, 2, 3, 4]\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWPUAct1q2Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logs_base_dir = \"runs/\"\n",
        "%tensorboard --logdir {logs_base_dir}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNsdkAGq5Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##%\n",
        "# Boxplot (loss reduction in test set)\n",
        "report_table_concat = pd.concat(report_table)\n",
        "cols_table = ['p_value','rho_user','%reduction_test']\n",
        "df_boxplot_table = pd.DataFrame(report_table_concat[cols_table])\n",
        "df_boxplot_table['label'] = df_boxplot_table.shape[0]*['$f(x)$']\n",
        "report_criteria_concat = pd.concat(report_criteria)\n",
        "columns_crit = ['rho_user','%reduction_test']\n",
        "df_boxplot_crit = pd.DataFrame(report_criteria_concat[columns_crit])\n",
        "df_boxplot_crit['label'] = df_boxplot_crit.shape[0]*['$g(x)$']\n",
        "# p-value median\n",
        "p_value_by_row_index = df_boxplot_table['p_value'].groupby(df_boxplot_table.index)\n",
        "p_value_median = p_value_by_row_index.median()\n",
        "# Boxplot (jaccard index in test set)\n",
        "columns_jac = ['rho_user','jaccard']\n",
        "df_jaccard = pd.DataFrame(report_criteria_concat[columns_jac])\n",
        "# Unfiltered Result dataframes\n",
        "cols_fx = ['rho_user','%reduction_val','budget','%reduction_test']\n",
        "results_fx = pd.DataFrame(report_table_concat[cols_fx])\n",
        "cols_fxgx = ['rho_user','%reduction_test', 'jaccard']\n",
        "results_fxgx = pd.concat([df_boxplot_table[cols_fxgx[:2]], df_boxplot_crit[cols_fxgx[1]], df_jaccard[cols_fxgx[2]]], axis=1)\n",
        "# Filter experiments with p_value > 0.05\n",
        "df_boxplot_crit = df_boxplot_crit.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "df_jaccard = df_jaccard.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "df_boxplot_table = df_boxplot_table.loc[df_boxplot_table['p_value'] <= 0.05]\n",
        "# Boxplot with filtered values only\n",
        "frames = [df_boxplot_table, df_boxplot_crit]\n",
        "df = pd.concat(frames)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OumIYSVNq7Zj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Avoid plotting when median(p_value)>0.5\n",
        "for i in range(p_value_median.shape[0]):\n",
        "    if p_value_median.iloc[i]>0.05:\n",
        "      df.loc[df.index==i,'%reduction_test'] = np.nan\n",
        "      df_jaccard.loc[df_jaccard.index==i, 'jaccard'] = np.nan"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6d4xyQvq952",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "65b04d0f-7dcb-4447-b710-9728a87b0bd3"
      },
      "source": [
        "# Dataframe for results f(x)\n",
        "results_fx_by_row_index = results_fx.groupby(results_fx.index)\n",
        "fx_median = results_fx_by_row_index.median()\n",
        "fx_q1 = results_fx_by_row_index.quantile(q=0.25)\n",
        "fx_q3 = results_fx_by_row_index.quantile(q=0.75)\n",
        "# Signaling function statistics (median(q1-q3)) LaTex\n",
        "output_fx = io.StringIO()\n",
        "numRows = fx_median.shape[0]\n",
        "numCols = fx_median.shape[1]\n",
        "output_fx.write(\"results_fx (\\\\rho|%reduction_val|sig_rate|%reduction_test|H0)\\n\")\n",
        "output_fx.write(\"----------\\n\")\n",
        "for i in range(numRows):\n",
        "  row = [r'{:.2f}'.format(val1) if p_value_median[i]>0.05 and j==0 else r'{}' if p_value_median[i]>0.05 and j!=0\\\n",
        "         else r'{:.2f}'.format(val1) if (j==0) else r'{:.2f}({:.2f}-{:.2f})'.format(val1,val2,val3) if (j==2)\\\n",
        "         else r'{:.1f}({:.1f}-{:.1f})'.format(val1,val2,val3) for val1,val2,val3,j in zip(fx_median.iloc[i],fx_q1.iloc[i],fx_q3.iloc[i],range(numCols))]\n",
        "  output_fx.write(\"{{}} & {{}} & %s & {H0} \\\\\\\\\\n\".format(H0=r'$\\surd$' if p_value_median[i]<=0.05 else r'$\\times$')%(\" & \".join(row)))\n",
        "print(output_fx.getvalue())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results_fx (\\rho|%reduction_val|sig_rate|%reduction_test|H0)\n",
            "----------\n",
            "{} & {} & 0.01 & 3.8(3.6-4.2) & 0.01(0.01-0.01) & 4.8(4.4-5.0) & $\\surd$ \\\\\n",
            "{} & {} & 0.05 & 15.4(15.3-16.0) & 0.06(0.05-0.06) & 18.0(17.1-18.6) & $\\surd$ \\\\\n",
            "{} & {} & 0.10 & 28.8(28.0-31.8) & 0.10(0.09-0.10) & 28.1(27.9-28.9) & $\\surd$ \\\\\n",
            "{} & {} & 0.15 & 39.2(38.8-44.1) & 0.14(0.14-0.15) & 37.8(37.4-40.0) & $\\surd$ \\\\\n",
            "{} & {} & 0.20 & 49.2(47.8-53.1) & 0.20(0.20-0.20) & 46.7(45.6-49.9) & $\\surd$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjL-JtRhrC6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "f34f89d2-6267-4544-9de3-7d85e3a883fa"
      },
      "source": [
        "# Dataframe for comparison f(x)-g(x)\n",
        "results_fxgx_by_row_index = results_fxgx.groupby(results_fxgx.index)\n",
        "fxgx_median = results_fxgx_by_row_index.median()\n",
        "fxgx_q1 = results_fxgx_by_row_index.quantile(q=0.25)\n",
        "fxgx_q3 = results_fxgx_by_row_index.quantile(q=0.75)\n",
        "# Baseline comparison statistics (median(q1-q3)) LaTex\n",
        "output_fxgx = io.StringIO()\n",
        "numRows = fxgx_median.shape[0]\n",
        "numCols = fxgx_median.shape[1]\n",
        "output_fxgx.write(\"results_fxgx (\\\\rho|%reduction_test(fx)|%reduction_test(fxgx)|Jaccard|H0\\n\")\n",
        "output_fxgx.write(\"------------\\n\")\n",
        "for i in range(numRows):\n",
        "  row = [r'{:.2f}'.format(val1) if p_value_median[i]>0.05 and j==0 else r'{}' if p_value_median[i]>0.05 and j!=0\\\n",
        "         else r'{:.2f}'.format(val1) if (j==0) else r'{:.2f}({:.2f}-{:.2f})'.format(val1,val2,val3) if (j==3)\\\n",
        "         else r'{:.1f}({:.1f}-{:.1f})'.format(val1,val2,val3) for val1,val2,val3,j in zip(fxgx_median.iloc[i],fxgx_q1.iloc[i],fxgx_q3.iloc[i],range(numCols))]\n",
        "  output_fxgx.write(\"{{}} & {{}} & %s & {H0} \\\\\\\\\\n\".format(H0=r'$\\surd$' if p_value_median[i]<=0.05 else r'$\\times$')%(\" & \".join(row)))\n",
        "print(output_fxgx.getvalue())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "results_fxgx (\\rho|%reduction_test(fx)|%reduction_test(fxgx)|Jaccard|H0\n",
            "------------\n",
            "{} & {} & 0.01 & 4.8(4.4-5.0) & 2.4(1.5-2.7) & 0.98(0.98-0.99) & $\\surd$ \\\\\n",
            "{} & {} & 0.05 & 18.0(17.1-18.6) & 14.2(11.5-14.9) & 0.94(0.92-0.95) & $\\surd$ \\\\\n",
            "{} & {} & 0.10 & 28.1(27.9-28.9) & 28.2(23.6-28.4) & 0.90(0.88-0.92) & $\\surd$ \\\\\n",
            "{} & {} & 0.15 & 37.8(37.4-40.0) & 35.1(31.3-37.8) & 0.86(0.84-0.90) & $\\surd$ \\\\\n",
            "{} & {} & 0.20 & 46.7(45.6-49.9) & 43.3(41.6-48.1) & 0.83(0.81-0.87) & $\\surd$ \\\\\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0X7KJ6trNGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%%\n",
        "# Save results in csv fomat\n",
        "path_csv = \"drive/My Drive/NIPS2020/results/imdb/results_{clf}_yhat{yhat}_pca{pca}.csv\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "results = pd.concat([results_fx, results_fxgx], keys=['fx', 'fxgx'], axis=1).to_csv(path_csv, index=True, header=True)\n",
        "# Save results in tex fomat\n",
        "L = [output_fx.getvalue(),output_fxgx.getvalue()]\n",
        "path_txt = \"drive/My Drive/NIPS2020/results/imdb/results_{clf}_yhat{yhat}_pca{pca}.txt\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "txt = open(path_txt, \"w\") \n",
        "txt.writelines(L) \n",
        "txt.close() #to change file access modes"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTFKkXsrQOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7149c4de-8f18-4f5a-cb35-6130a2c75e07"
      },
      "source": [
        "fig, ax = plt.subplots(1,2,figsize=(15, 5.1), constrained_layout=False, dpi=90)\n",
        "pal = sns.color_palette('Paired')\n",
        "sns.boxplot(x=df['rho_user'], y=df['%reduction_test'], hue='label', data=df, ax=ax[0], palette=pal)\n",
        "ax[0].set_xlabel(r'budget $\\rho$')\n",
        "ax[0].set_ylabel(r'Loss reduction $r_{test}(\\%)$')\n",
        "ax[0].legend(loc='upper left')\n",
        "pal = sns.color_palette('BuGn_r')\n",
        "sns.boxplot(x=df_jaccard['rho_user'], y=df_jaccard['jaccard'], data=df_jaccard, ax=ax[1], palette=pal)\n",
        "ax[1].set_xlabel(r'budget $\\rho$')\n",
        "ax[1].set_ylabel(r'Jaccard index $J$')\n",
        "plt.tight_layout()\n",
        "path_fig_fxgx = \"drive/My Drive/NIPS2020/results/imdb/fig_fxgx_{clf}_yhat{yhat}_pca{pca}.pdf\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "plt.savefig(path_fig_fxgx, bbox_inches='tight', facecolor='w')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1350x459 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlQtQPDGFE9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reverse lookup\n",
        "INDEX_FROM = 3\n",
        "word_to_id = tf.keras.datasets.imdb.get_word_index()\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "word_to_id[\"<START>\"] = 1\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj6x1QVqcRgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "37b11eda-4c60-431b-9023-e0e776ac9eac"
      },
      "source": [
        "rho = 0.01\n",
        "rule = table_best.loc[table_best.rho_user == rho]['rule'].to_numpy()\n",
        "eta = table_best.loc[table_best.rho_user == rho]['eta'].to_numpy()[0]\n",
        "theta = crit_table_best.loc[crit_table_best.rho_user == rho]['thresh'].to_numpy()[0]\n",
        "f_test = exp_best.gpr_mean_test+rule*np.sqrt(exp_best.gpr_var_test)\n",
        "top_n = 20 # Top n selected instances in test set\n",
        "top_f_idx = np.argpartition(f_test, -top_n)[-top_n:]\n",
        "if clf=='svm':\n",
        "    crit_test = np.abs(y_test_pred_soft_best.ravel())\n",
        "    top_crit_idx = np.argpartition(crit_test, top_n)[:top_n]\n",
        "elif clf=='softmax':\n",
        "    p_test = np.concatenate((y_test_pred_soft_best,1-y_test_pred_soft_best),axis=1)\n",
        "    crit_test = entropy(p_test, axis=1, base=2)\n",
        "    top_crit_idx = np.argpartition(crit_test, -top_n)[-top_n:]\n",
        "output_text = io.StringIO()\n",
        "print('eta={},theta={}'.format(eta,theta))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eta=0.7773538157343864,theta=0.9994109869003296\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGqv4gVyc1kF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0b6bc494-ce91-429a-9c60-4e60b2d7bc94"
      },
      "source": [
        "output_text.write(\"top_n={}, rho_user={}, g(x)={}, addh_hat={}, PCA={}\\n\".format(top_n,rho,clf, addPredictions, applyPCA))\n",
        "output_text.write(\"|f(x)>eta|={}(eta={:.3f}), |g(x)>theta|={}(theta={:.3f})\\n\".format(np.sum(f_test>eta), eta, np.sum(crit_test<theta) if clf=='svm' else np.sum(crit_test>theta), theta))\n",
        "output_text.write(\"\\nTop misclassfied instances picked by f(x)\\n\")\n",
        "output_text.write(\"-----------------------------------------\\n\")\n",
        "for i in top_f_idx:\n",
        "  cond = f_test[i]>eta\n",
        "  if y_test_best[i] != y_test_pred_th_best[i] and cond:\n",
        "    output_text.write(' '.join([id_to_word[id] for id in X_test_best[i,:] if id!=0])+\\\n",
        "        '\\n y={}'.format(y_test_best[i])+', y_pred={}'.format(y_test_pred_th_best[i])+\\\n",
        "        ', g(x)({})={:.3f}'.format('D' if clf=='svm' else 'H', crit_test[i])+\\\n",
        "        ', f(x)={:.3f}'.format(f_test[i])+'\\n\\n')\n",
        "print(output_text.getvalue())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=12(eta=0.777), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> if the lion king is a serious story about a young lion growing up to <UNK> his father's death the lion king 1 and a half is the total opposite full of <UNK> and <UNK> the lion king told the story from the side of <UNK> the young lion 1 and a half is from the view of <UNK> and <UNK> a less than perfect duo made up of a <UNK> who left home because he could not dig <UNK> without <UNK> his friends and neighbors and a <UNK> who has an <UNK> issue the movie is a little short on substance but disney does a good job of <UNK> time with various <UNK> starring <UNK> and <UNK> as they watch the movie with us my favorite is the sing along that happens halfway through the movie make sure you watch the <UNK> <UNK> disney has <UNK> 1 and a half as the rest of the story though it really isn't it is just a different perspective of the lion king without all of the serious stuff that <UNK> most of the second half of the original disney classic credit <UNK> lane as <UNK> and <UNK> <UNK> as <UNK> for their voice work without their efforts the movie may not have worked the sing they entertain and they make us laugh they also give us a reason to avoid a hot <UNK> with a <UNK>\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.899\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhsLRvmXO-Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "279cff12-9e6e-426c-f17f-65e9eaaee5fd"
      },
      "source": [
        "output_text.write(\"\\nTop misclassfied instances picked by g(x)\\n\")\n",
        "output_text.write(\"-----------------------------------------\\n\")\n",
        "for i in top_crit_idx:\n",
        "  cond = crit_test[i]<theta if clf=='svm' else crit_test[i]>theta\n",
        "  if y_test_best[i] != y_test_pred_th_best[i]:\n",
        "    output_text.write(' '.join([id_to_word[id] for id in X_test_best[i,:] if id!=0])+\\\n",
        "        '\\n y={}'.format(y_test_best[i])+', y_pred={}'.format(y_test_pred_th_best[i])+\\\n",
        "        ', g(x)({})={:.3f}'.format('D' if clf=='svm' else 'H', crit_test[i])+\\\n",
        "        ', f(x)={:.3f}'.format(f_test[i])+'\\n\\n')\n",
        "print(output_text.getvalue())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_n=20, rho_user=0.01, g(x)=softmax, addh_hat=True, PCA=False\n",
            "|f(x)>eta|=12(eta=0.777), |g(x)>theta|=14(theta=0.999)\n",
            "\n",
            "Top misclassfied instances picked by f(x)\n",
            "-----------------------------------------\n",
            "<START> if the lion king is a serious story about a young lion growing up to <UNK> his father's death the lion king 1 and a half is the total opposite full of <UNK> and <UNK> the lion king told the story from the side of <UNK> the young lion 1 and a half is from the view of <UNK> and <UNK> a less than perfect duo made up of a <UNK> who left home because he could not dig <UNK> without <UNK> his friends and neighbors and a <UNK> who has an <UNK> issue the movie is a little short on substance but disney does a good job of <UNK> time with various <UNK> starring <UNK> and <UNK> as they watch the movie with us my favorite is the sing along that happens halfway through the movie make sure you watch the <UNK> <UNK> disney has <UNK> 1 and a half as the rest of the story though it really isn't it is just a different perspective of the lion king without all of the serious stuff that <UNK> most of the second half of the original disney classic credit <UNK> lane as <UNK> and <UNK> <UNK> as <UNK> for their voice work without their efforts the movie may not have worked the sing they entertain and they make us laugh they also give us a reason to avoid a hot <UNK> with a <UNK>\n",
            " y=1, y_pred=0, g(x)(H)=0.998, f(x)=0.899\n",
            "\n",
            "\n",
            "Top misclassfied instances picked by g(x)\n",
            "-----------------------------------------\n",
            "<START> <UNK> is another one of those <UNK> films that <UNK> flynn was making in the last decade of his life trying to support his family and stay out of trouble with the <UNK> it's a remake of the fred <UNK> <UNK> <UNK> film <UNK> from a decade ago br br unlike that studio product <UNK> has the advantage of that great location cinematography right at the sight of the golden <UNK> but <UNK> flynn who was aging <UNK> before the camera in every film was way too old to be playing these action adventure types any longer his scenes with <UNK> <UNK> really do lack <UNK> br br as for <UNK> she plays <UNK> former <UNK> who through the <UNK> of being saved from a fire now has <UNK> she both doesn't remember <UNK> and is now married to <UNK> <UNK> br br but <UNK> got some nasty people led by martin <UNK> and <UNK> <UNK> who are after some <UNK> which have come into his <UNK> got to deal with them too br br best reason to see <UNK> is to hear <UNK> king cole sing and play the piano most people today don't realize that cole was an accomplished jazz <UNK> they only think of him as a singer actually he was a <UNK> first the singing was an <UNK> br br <UNK> is a routine action adventure film for those who are fans of that type of movie\n",
            " y=0, y_pred=1, g(x)(H)=0.999, f(x)=0.553\n",
            "\n",
            "<START> i rented the film i don't think it got a theatrical release here out expecting the worse the <UNK> made the film look awful i was in fact very surprised it was well worth watching it was loosely scripted almost like an ensemble piece of film it had some very funny moments in it and although flawed is an effective satire on the show and the people on the show without being too <UNK> it is flawed mainly by the awful soundtrack of <UNK> <UNK> effects but on the whole it comes across as honest and generally true to form of the show in an <UNK> or larry <UNK> way br br at the moment it is the fashion to be critical of jerry <UNK> he is also an easy target <UNK> could have made citizen kane and it would be <UNK> 'the worst film ever <UNK> i recommend this film for anybody interested in the show a flawed but innovative and interesting piece of film\n",
            " y=1, y_pred=0, g(x)(H)=0.999, f(x)=0.601\n",
            "\n",
            "<START> so halfway through the season i got so caught up in school and my activities that i didn't realize that the show had been <UNK> halfway through which is crap br br i think the <UNK> of this show should write fox and ask them to at least finish filming so that a the season can be released on dvd later maybe then they'll see how many people were disappointed that the show didn't survive its first season br br i loved the show and looked forward to it every <UNK> after the <UNK> can you imagine my disappointment when i came back to try and watch the show only to discover that it had disappeared needless to say i'm not very happy with fox right now even more so after <UNK> that no ending was filmed i mean if you're going to work on a project at least finish it to see what happens a half filmed show is like a half made car it's pretty much useless fox film the damn ending and give some of the show's fans some peace\n",
            " y=1, y_pred=0, g(x)(H)=0.999, f(x)=0.334\n",
            "\n",
            "<START> i love this movie it's wacky funny violent surreal played out in a <UNK> head and definitely not your usual comedy br br if you don't find the film amusing then i guess it's just not for your <UNK> so this is a tough one to write a review for br br for reference some other comedies i love are the big <UNK> the princess bride and <UNK> that one only got me the second time around there are others but my taste is definitely for the unusual and i am willing to accept that most people just don't tend to like that kind of thing i make no <UNK> for having an unusual sense of humour at least i have one br br the scenes and characters of this particular movie are well put together the <UNK> humour is hilarious the situations are intriguing the acting is very good as you would expect of the cast though the acting demands made of the cast by the script are not particularly high the overall <UNK> makes for fun funny watchable yet violent entertainment\n",
            " y=1, y_pred=0, g(x)(H)=1.000, f(x)=0.655\n",
            "\n",
            "<START> anyone who saw the original <UNK> movie knows how an excellent cast script and director can put together a comedy masterpiece by the same <UNK> it's easy to see how the opposite of that can create another <UNK> hollywood bore a <UNK> this movie was pathetic had it not been for john <UNK> a comic genius i would have walked out about 15 minutes into this dreadful waste of celluloid br br neil simon wouldn't write another screenplay for this version he said that he couldn't improve on the first and i'm surprised that after this cinematic <UNK> he wouldn't sue for <UNK> of humor br br jack lemmon and <UNK> dennis did such a wonderful job in the original what were the producers thinking about when they cast this one how could the director and editor look at these scenes and think any of them were funny i don't know but one thing i do know it's no surprise why foreign and independent movies are becoming more and more popular\n",
            " y=0, y_pred=1, g(x)(H)=1.000, f(x)=0.771\n",
            "\n",
            "<START> too much of something borrowed grade b br br super <UNK> sunday is one of the <UNK> days at movie theaters every year because of this movie studios tend to avoid <UNK> bigger <UNK> films that weekend every few years a studio <UNK> a counter <UNK> female <UNK> movie <UNK> the wedding <UNK> to <UNK> with the big game this super <UNK> weekend similarly titled the wedding date will try to find success and <UNK> viewers not watching the game br br sick of people feeling sorry for her single woman <UNK> <UNK> <UNK> <UNK> <UNK> will and grace <UNK> male <UNK> nick <UNK> <UNK> about <UNK> to <UNK> as her boyfriend for her <UNK> wedding in london her family has been giving her a hard time about her not being married and her ex <UNK> of seven years who <UNK> her without a reason is the best man to make him jealous <UNK> <UNK> nick around her ex to make him see what he is missing but ultimately nick helps <UNK> realize that she can open up and let someone love her br br the film <UNK> too much from similar wedding movies it is almost a <UNK> copy of <UNK> picture perfect and <UNK> in scenes similar to the wedding <UNK> and my best friends wedding the movie also has a <UNK> pretty women theme going for it and knowing her audience the director makes clever references to that and other films br br the wedding date has all the clichéd elements of a typical wedding movie there is the stereotypical <UNK> mother <UNK> taylor <UNK> blonde and practically <UNK> wedding <UNK> by the family and friends at the wedding and <UNK> dinner the twist at the ending has been done before but it was something that wasn't completely expected the real reason why <UNK> was <UNK> comes as a surprise and changes the direction of the film for the last half hour br br even though the wedding date is predictable it is able to stand on its own <UNK> <UNK> in her first lead role proves she can be charming and funny <UNK> <UNK> has great chemistry with <UNK> <UNK> but most of his dialogue was too corny and unrealistic he is able to make best of what he is given and be able to <UNK> the character br br by the use of many clever <UNK> often sexual the film is actually funny although primarily a chick flick the film has <UNK> everyone can enjoy the feel good story and humor make it the best date movie released in a long time\n",
            " y=0, y_pred=1, g(x)(H)=0.999, f(x)=0.683\n",
            "\n",
            "<START> the godfather of television but aside from it's <UNK> and <UNK> characters the two are nothing alike tony <UNK> is forced to go to a psychiatrist after a series of panic attacks his psychiatrist learns that tony is actually part of two families in one family he is a loving father yet not so perfect husband and in the other family he is a ruthless <UNK> after analysis dr <UNK> <UNK> that <UNK> problems actually <UNK> from his mother <UNK> who's <UNK> to have <UNK> personality <UNK> <UNK> is <UNK> <UNK> as the main character yet <UNK> and <UNK> aren't nearly as recognized for their equally and talented performances as the psychiatrist and mother <UNK> <UNK> <UNK> and <UNK> are <UNK> for their brilliant supporting roles van <UNK> from the e street band plays his first and only role as <UNK> best friend and is quite convincing and <UNK> <UNK> the only <UNK> actor to have actually appeared in a godfather film plays <UNK> uncle and on and off <UNK> many fans also enjoyed characters played by <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> and <UNK> <UNK> children are okay but not notable with the exception of <UNK> stunning performance in the third to last episode the second coming <UNK> and <UNK> are unconvincing and over the top but the show is too strong for them to hold it back even as the show continues for over six season it <UNK> to have a dull or predictable moment br br out of four\n",
            " y=1, y_pred=0, g(x)(H)=1.000, f(x)=0.640\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH-thpd8rmTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_txt = \"drive/My Drive/NIPS2020/results/imdb/instances_{clf}_yhat{yhat}_pca{pca}.txt\".format(clf=clf, pca=applyPCA, yhat=addPredictions)\n",
        "txt = open(path_txt, \"w\") \n",
        "txt.writelines(output_text.getvalue()) \n",
        "txt.close() #to change file access modes"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX7WuJijg-Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "report_table_concat = pd.concat(report_table)\n",
        "table_by_row_index = report_table_concat.groupby(report_table_concat.index)\n",
        "report_table_mean = table_by_row_index.mean()\n",
        "report_table_std = table_by_row_index.std()\n",
        "\n",
        "report_criteria_concat = pd.concat(report_criteria)\n",
        "table_by_row_index = report_criteria_concat.groupby(report_criteria_concat.index)\n",
        "report_criteria_mean = table_by_row_index.mean()\n",
        "report_criteria_std = table_by_row_index.std()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zDE3LuFiAvg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "8561aab0-af6f-4211-d048-a2abb77bf548"
      },
      "source": [
        "report_table_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.06</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00560</td>\n",
              "      <td>0.14192</td>\n",
              "      <td>3.786</td>\n",
              "      <td>0.820517</td>\n",
              "      <td>1.596467e-04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.1471</td>\n",
              "      <td>3.218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02472</td>\n",
              "      <td>0.12280</td>\n",
              "      <td>16.776</td>\n",
              "      <td>0.672585</td>\n",
              "      <td>1.438608e-20</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0247</td>\n",
              "      <td>0.1273</td>\n",
              "      <td>16.284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.84</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04568</td>\n",
              "      <td>0.10184</td>\n",
              "      <td>31.026</td>\n",
              "      <td>0.448278</td>\n",
              "      <td>2.111505e-39</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0457</td>\n",
              "      <td>0.1063</td>\n",
              "      <td>30.058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.26</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06064</td>\n",
              "      <td>0.08688</td>\n",
              "      <td>41.244</td>\n",
              "      <td>0.423398</td>\n",
              "      <td>1.133743e-41</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.154</td>\n",
              "      <td>0.0634</td>\n",
              "      <td>0.0886</td>\n",
              "      <td>41.738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.12</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>0.07376</td>\n",
              "      <td>50.104</td>\n",
              "      <td>0.136592</td>\n",
              "      <td>5.266706e-43</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.0775</td>\n",
              "      <td>0.0745</td>\n",
              "      <td>50.980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rule  rho_user  error_val  ...  error_test  L_test  %reduction_test\n",
              "0  1.06      0.01    0.00560  ...      0.0049  0.1471            3.218\n",
              "1  1.20      0.05    0.02472  ...      0.0247  0.1273           16.284\n",
              "2  0.84      0.10    0.04568  ...      0.0457  0.1063           30.058\n",
              "3  1.26      0.15    0.06064  ...      0.0634  0.0886           41.738\n",
              "4  0.12      0.20    0.07376  ...      0.0775  0.0745           50.980\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zgyJyu4iCBQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "cb39105f-bc61-49e2-e1ff-25a644cd23fe"
      },
      "source": [
        "report_criteria_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00488</td>\n",
              "      <td>0.14264</td>\n",
              "      <td>3.306</td>\n",
              "      <td>0.998604</td>\n",
              "      <td>0.012</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.1463</td>\n",
              "      <td>3.672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.05</td>\n",
              "      <td>0.02320</td>\n",
              "      <td>0.12432</td>\n",
              "      <td>15.728</td>\n",
              "      <td>0.964553</td>\n",
              "      <td>0.054</td>\n",
              "      <td>0.0242</td>\n",
              "      <td>0.1278</td>\n",
              "      <td>15.878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.04408</td>\n",
              "      <td>0.10344</td>\n",
              "      <td>29.916</td>\n",
              "      <td>0.885287</td>\n",
              "      <td>0.102</td>\n",
              "      <td>0.0452</td>\n",
              "      <td>0.1068</td>\n",
              "      <td>29.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.15</td>\n",
              "      <td>0.06088</td>\n",
              "      <td>0.08664</td>\n",
              "      <td>41.324</td>\n",
              "      <td>0.774637</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.0654</td>\n",
              "      <td>0.0866</td>\n",
              "      <td>43.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.07608</td>\n",
              "      <td>0.07144</td>\n",
              "      <td>51.648</td>\n",
              "      <td>0.668580</td>\n",
              "      <td>0.206</td>\n",
              "      <td>0.0825</td>\n",
              "      <td>0.0695</td>\n",
              "      <td>54.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val    L_val  ...  error_test  L_test  %reduction_test\n",
              "0      0.01    0.00488  0.14264  ...      0.0057  0.1463            3.672\n",
              "1      0.05    0.02320  0.12432  ...      0.0242  0.1278           15.878\n",
              "2      0.10    0.04408  0.10344  ...      0.0452  0.1068           29.700\n",
              "3      0.15    0.06088  0.08664  ...      0.0654  0.0866           43.020\n",
              "4      0.20    0.07608  0.07144  ...      0.0825  0.0695           54.300\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neU88XQkAzny",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4b792c43-3fdb-48ee-d89a-e251ef90f666"
      },
      "source": [
        "report_table_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rule</th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>eta</th>\n",
              "      <th>p_value</th>\n",
              "      <th>check</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.176010</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001265</td>\n",
              "      <td>0.007034</td>\n",
              "      <td>0.797076</td>\n",
              "      <td>0.219716</td>\n",
              "      <td>3.569270e-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001817</td>\n",
              "      <td>0.009283</td>\n",
              "      <td>1.190869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.104536</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.003025</td>\n",
              "      <td>0.007595</td>\n",
              "      <td>2.114800</td>\n",
              "      <td>0.264298</td>\n",
              "      <td>3.187349e-20</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.009425</td>\n",
              "      <td>1.828026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.221884</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002918</td>\n",
              "      <td>0.007857</td>\n",
              "      <td>2.533146</td>\n",
              "      <td>0.322871</td>\n",
              "      <td>4.721467e-39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.006535</td>\n",
              "      <td>0.008526</td>\n",
              "      <td>3.697022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.047855</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004495</td>\n",
              "      <td>0.010188</td>\n",
              "      <td>4.406856</td>\n",
              "      <td>0.203426</td>\n",
              "      <td>2.432024e-41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006628</td>\n",
              "      <td>0.008569</td>\n",
              "      <td>3.804684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005127</td>\n",
              "      <td>0.009045</td>\n",
              "      <td>4.302619</td>\n",
              "      <td>0.043197</td>\n",
              "      <td>1.177661e-42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.010186</td>\n",
              "      <td>0.009670</td>\n",
              "      <td>5.632673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       rule  rho_user  error_val  ...  error_test    L_test  %reduction_test\n",
              "0  1.176010       0.0   0.001265  ...    0.001817  0.009283         1.190869\n",
              "1  1.104536       0.0   0.003025  ...    0.002564  0.009425         1.828026\n",
              "2  1.221884       0.0   0.002918  ...    0.006535  0.008526         3.697022\n",
              "3  1.047855       0.0   0.004495  ...    0.006628  0.008569         3.804684\n",
              "4  0.178885       0.0   0.005127  ...    0.010186  0.009670         5.632673\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjaMD-kKNMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "95ed1e63-79df-4e52-e414-e7a7d519ef96"
      },
      "source": [
        "report_criteria_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rho_user</th>\n",
              "      <th>error_val</th>\n",
              "      <th>L_val</th>\n",
              "      <th>%reduction_val</th>\n",
              "      <th>thresh</th>\n",
              "      <th>budget</th>\n",
              "      <th>error_test</th>\n",
              "      <th>L_test</th>\n",
              "      <th>%reduction_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000996</td>\n",
              "      <td>0.007357</td>\n",
              "      <td>0.659454</td>\n",
              "      <td>0.000779</td>\n",
              "      <td>0.004472</td>\n",
              "      <td>0.003054</td>\n",
              "      <td>0.007032</td>\n",
              "      <td>1.738094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.006832</td>\n",
              "      <td>1.788413</td>\n",
              "      <td>0.016886</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>0.003347</td>\n",
              "      <td>0.007023</td>\n",
              "      <td>1.419972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.002834</td>\n",
              "      <td>0.007164</td>\n",
              "      <td>2.081797</td>\n",
              "      <td>0.053454</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005251</td>\n",
              "      <td>0.006496</td>\n",
              "      <td>2.410187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.004625</td>\n",
              "      <td>0.007785</td>\n",
              "      <td>3.379797</td>\n",
              "      <td>0.081735</td>\n",
              "      <td>0.008367</td>\n",
              "      <td>0.005067</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>1.744506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005370</td>\n",
              "      <td>0.008341</td>\n",
              "      <td>4.106479</td>\n",
              "      <td>0.093708</td>\n",
              "      <td>0.008944</td>\n",
              "      <td>0.006225</td>\n",
              "      <td>0.006567</td>\n",
              "      <td>2.760860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rho_user  error_val     L_val  ...  error_test    L_test  %reduction_test\n",
              "0       0.0   0.000996  0.007357  ...    0.003054  0.007032         1.738094\n",
              "1       0.0   0.002871  0.006832  ...    0.003347  0.007023         1.419972\n",
              "2       0.0   0.002834  0.007164  ...    0.005251  0.006496         2.410187\n",
              "3       0.0   0.004625  0.007785  ...    0.005067  0.005878         1.744506\n",
              "4       0.0   0.005370  0.008341  ...    0.006225  0.006567         2.760860\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NU73I2FKP6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}